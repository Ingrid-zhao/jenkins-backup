Started by user [8mha:////4Kx/oAUYQ8g7/LgGNzq84mLZKZrt10b7R/6+ApQ6bUDJAAAAnB+LCAAAAAAAAP9b85aBtbiIQTGjNKU4P08vOT+vOD8nVc83PyU1x6OyILUoJzMv2y+/JJUBAhiZGBgqihhk0NSjKDWzXb3RdlLBUSYGJk8GtpzUvPSSDB8G5tKinBIGIZ+sxLJE/ZzEvHT94JKizLx0a6BxUmjGOUNodHsLgAz+EgYB/dLi1CL91IrUZN3ElNzMPABRT8TSxQAAAA==[0mexecution admin
Running in Durability level: MAX_SURVIVABILITY
[8mha:////4DOlrZhma2TKYqx8mtRBwGXVE8Xt4z3OJyo/zi+ICDdzAAAAoh+LCAAAAAAAAP9tjTEOwjAQBM8BClpKHuFItIiK1krDC0x8GCfWnbEdkooX8TX+gCESFVvtrLSa5wtWKcKBo5UdUu8otU4GP9jS5Mixv3geZcdn2TIl9igbHBs2eJyx4YwwR1SwULBGaj0nRzbDRnX6rmuvydanHMu2V1A5c4MHCFXMWcf8hSnC9jqYxPTz/BXAFEIGsfuclm8zQVqFvQAAAA==[0m[Pipeline] Start of Pipeline
[8mha:////4B4K7nOhvaaLmbeE3w0NEhE1GAALwLDjakw9plXgkY6XAAAApR+LCAAAAAAAAP9tjTEOwjAUQ3+KOrAycohUghExsUZZOEFIQkgb/d8mKe3EibgadyBQiQlLlmxL1nu+oE4RjhQdby12HpP2vA+jK4lPFLtroIm3dOGaMFGwXNpJkrGnpUrKFhaxClYC1hZ1oOTRZdiIVt1VExS65pxj2Q4CKm8GeAAThZxVzN8yR9jeRpMIf5y/AJj7DGxXvP/86jduZBmjwAAAAA==[0m[Pipeline] node
Running on [8mha:////4EheNQ7D4c27QswDGPiDpGtf9rfQF1HauEmyd+/REsZ/AAAAoh+LCAAAAAAAAP9b85aBtbiIQTGjNKU4P08vOT+vOD8nVc83PyU1x6OyILUoJzMv2y+/JJUBAhiZGBgqihhk0NSjKDWzXb3RdlLBUSYGJk8GtpzUvPSSDB8G5tKinBIGIZ+sxLJE/ZzEvHT94JKizLx0a6BxUmjGOUNodHsLgAyeEgZx/eT83ILSktQiICOvpCg/Jye1SDdLHwCRPP8lzAAAAA==[0mcontroller-j in /root/.jenkins/workspace/spr-test-nicIperfTcpGuestsStress
[8mha:////4NUxBMzN6CtFAbQ4pdo7pH8ZuwVHigLf0SdP3FcjQTwyAAAApR+LCAAAAAAAAP9tjTEOwjAUQ3+KOrAycoh0gA0xsUZZOEFIQkgb/d8mKe3EibgadyBQiQlLlmxL1nu+oE4RjhQdby12HpP2vA+jK4lPFLtroIm3dOGaMFGwXNpJkrGnpUrKFhaxClYC1hZ1oOTRZdiIVt1VExS65pxj2Q4CKm8GeAAThZxVzN8yR9jeRpMIf5y/AJj7DGxXvP/86jfoP95RwAAAAA==[0m[Pipeline] {
[8mha:////4OCB1+Up79PmV3LnMeomKr9r+JFCKkFjAfTpr2UorbLOAAAApR+LCAAAAAAAAP9tjTEOwjAUQ3+KOrAycoh0gQkxsUZZOEFIQkgb/d8mKe3EibgadyBQiQlLlmxL1nu+oE4RjhQdby12HpP2vA+jK4lPFLtroIm3dOGaMFGwXNpJkrGnpUrKFhaxClYC1hZ1oOTRZdiIVt1VExS65pxj2Q4CKm8GeAAThZxVzN8yR9jeRpMIf5y/AJj7DGxXvP/86jc09154wAAAAA==[0m[Pipeline] stage
[8mha:////4N6KQN35K8CT/Pcr9a+R4oOEu4uEh3phvpB1t67zd2hmAAAApR+LCAAAAAAAAP9tjTEOwjAUQ3+KOrAycoh0ggUxsUZZOEFIQkgb/d8mKe3EibgadyBQiQlLlmxL1nu+oE4RjhQdby12HpP2vA+jK4lPFLtroIm3dOGaMFGwXNpJkrGnpUrKFhaxClYC1hZ1oOTRZdiIVt1VExS65pxj2Q4CKm8GeAAThZxVzN8yR9jeRpMIf5y/AJj7DGxXvP/86jek7ggRwAAAAA==[0m[Pipeline] { (rm project dir)
[8mha:////4EWjgIQS1R18e39T6LdOu3ZpSMSXMburmKwxJHd8e163AAAApR+LCAAAAAAAAP9tjTEOwjAUQ3+KOrAycoh0gwExsUZZOEFIQkgb/d8mKe3EibgadyBQiQlLlmxL1nu+oE4RjhQdby12HpP2vA+jK4lPFLtroIm3dOGaMFGwXNpJkrGnpUrKFhaxClYC1hZ1oOTRZdiIVt1VExS65pxj2Q4CKm8GeAAThZxVzN8yR9jeRpMIf5y/AJj7DGxXvP/86jcChmMxwAAAAA==[0m[Pipeline] script
[8mha:////4NOJ/YVWDlnnBpjDdLKlLZkF5LrR387vblsx7fWhZkPlAAAApR+LCAAAAAAAAP9tjTEOwjAUQ3+KOrAycoh0BAkxsUZZOEFIQkgb/d8mKe3EibgadyBQiQlLlmxL1nu+oE4RjhQdby12HpP2vA+jK4lPFLtroIm3dOGaMFGwXNpJkrGnpUrKFhaxClYC1hZ1oOTRZdiIVt1VExS65pxj2Q4CKm8GeAAThZxVzN8yR9jeRpMIf5y/AJj7DGxXvP/86jfpX/cvwAAAAA==[0m[Pipeline] {
[8mha:////4MAm0moKTc8Eo2PcB0LgkHNHI7Xtf5Poej2Mf/l8xh/lAAAAoh+LCAAAAAAAAP9tjTEOAiEURD9rLGwtPQTbaoyVLaHxBMgiwpL/WWDdrTyRV/MOEjexcpJJ5k3zXm9Y5wQnSpZ7g73DrB2PYbR18YlSfws0cU9XrgkzBcOlmSR15rygpGJgCWtgJWBjUAfKDm2BrfDqodqg0LaXkup3FNC4boAnMFHNRaXyhTnB7j52mfDn+SuAORZg+9pD/AAeoCAqvAAAAA==[0m[Pipeline] sh
+ ls /root/.jenkins/workspace/spr-test-nicIperfTcpGuestsStress/npxtester
1.0.0.0001.version
conf
installation
libs
log_analyzer
README.md
testconf
testLibs
Tests
[8mha:////4F3BY6hez6Yn9lSF4dYULOlz4RwK0Fdsp1OYWtj0vxDtAAAAox+LCAAAAAAAAP9tjTEOwjAQBDdBFLSUPMKBDglR0VppeIFJjHFi3QX7QlLxIr7GH4iIRMVWO9PM641lijhydKqx1HpKlVdd6N301MCxvQYeVMMXVTElDlaVdii5tqcZSxaLeVmOhcbKUhU4eXKCtW7MwxTBkCvOEid30Mh9fccTmZ7KYqJ8YYzY3Po6Mf06fwMYO0G2F+S7bfcBITL9lL0AAAA=[0m[Pipeline] echo
dir is exists and rm dir
[8mha:////4KL1cTFlC/t8/0LRf71hJwxXIUFLIMviWtcIHXR2W8epAAAAox+LCAAAAAAAAP9tjbEOgjAURS8YB1dHP6KEzcQ4uTYsfkGFWgvNe9g+hMkv8tf8B4kkTt7pnrOc1xvrFHHk6FRrqfOUaq/6MLj5qZFjdw08qpYvqmZKHKyq7FhxY08LViwWy7IcK42NpTpw8uQEW92ahymCIVecJc7uoJH75o4nMj2XxUT5whSxuw1NYvp1/gYw9YJsL8jLsv8AYAPmjb0AAAA=[0m[Pipeline] sh
+ rm -rf /root/.jenkins/workspace/spr-test-nicIperfTcpGuestsStress/npxtester
[8mha:////4GzJynz9IX3CLl34e/1JpYOeLz7FDsqMtIihCtFGqNpZAAAAox+LCAAAAAAAAP9tjTEOwjAQBDdBFLSUPMIRVEiIitZKwwtMYowT6y7YF5KKF/E1/kBEJCq22plmXm8sU8SRo1ONpdZTqrzqQu+mpwaO7TXwoBq+qIopcbCqtEPJtT3NWLJYzMtyLDRWlqrAyZMTrHVjHqYIhlxxlji5g0bu6zueyPRUFhPlC2PE5tbXienX+RvA2HWCfLsTZPsPzjQzob0AAAA=[0m[Pipeline] }
[8mha:////4MvApYhNLg1xEFG2iXyHCog7Z9h4MbdAsNSDoK4wJnDgAAAApB+LCAAAAAAAAP9tjTEOwjAQBDdBFLSUPMIRoqBAVLRWGl5gEmOcWHfBvpBUvIiv8QciIlGx1c4083pjmSKOHJ1qLLWeUuVVF3o3PTVwbK+BB9XwRVVMiYNVpR1Kru1pxpLFYl6WY6GxslQFTp6cYK0b8zBFMOSKs8TJHTRyX9/xRKanspgoXxgjNre+Tky/zt8Axq4T5NudINt/AO8A7Ay9AAAA[0m[Pipeline] // script
[8mha:////4P1g47DHQeYIMdAQPrqVFJW5XTEYSJkMqP0k+p1upCWxAAAApB+LCAAAAAAAAP9tjTEOwjAQBDdBFLSUPMIREqJBVLRWGl5gEmOcWHfBvpBUvIiv8QciIlGx1c4083pjmSKOHJ1qLLWeUuVVF3o3PTVwbK+BB9XwRVVMiYNVpR1Kru1pxpLFYl6WY6GxslQFTp6cYK0b8zBFMOSKs8TJHTRyX9/xRKanspgoXxgjNre+Tky/zt8Axq4T5NudINt/AGnsy8m9AAAA[0m[Pipeline] }
[8mha:////4Lc6WrLYEiiAC7rTWY8q4RQPGu1FD+hrgClvEqpzcg2sAAAAox+LCAAAAAAAAP9tjTESgjAQRT84FraWHiKMBZVjZZuh8QQRYgxkdjFZhMoTeTXvICMzVv7qv9e81xvrFHHk6FRrqfOUaq/6MLj5qZFjdw08qpYvqmZKHKyq7FhxY08LViwWy7IcK42NpTpw8uQEW92ahymCIVecJc7uoJH75o4nMj2XxUT5whSxuw1NYvp1/gYw9b0g35eCrPwAY5Sibb0AAAA=[0m[Pipeline] // stage
[8mha:////4LPzYIRsJlP9vBl87WR2FbvV5590n9jZkqHCRBijPEs5AAAApx+LCAAAAAAAAP9tjTEOwjAQBM9BKWgpeYQjJESDqGgtN7zAxMY4se6CfSGpeBFf4w8EIlGx1c5Kq3m+oMwJDpS8bBy2AXMdZBd7PzU5UGovkQbZ0FnWhJmik9oNmqw7zqiJHcwRBSwULB3WkXJAz7BSjbmbKhr01YnTtO0VFMHe4AFCTWY2ib8wJlhfe5sJf56/Ahg7BrFlKDa7z7F8A6sHc4fBAAAA[0m[Pipeline] stage
[8mha:////4P0yjWfQiEwQxZO7i9obwDXrYwQclNR3i//1CTGbFwBFAAAApx+LCAAAAAAAAP9tjTEOwjAUQ3+LOrAycohULDAgpq5RFk4QmhDSRv+Xn5R24kRcjTvQUokJD5ZtyXqvNxSR4UTsRGOx9RhrL7rQuymJgbi9BhpEQxdRE0YKVig7KDK2WqqiZGFRlsNKwtpiHSh6dAk2stEPXQaNrjwnnrajhNybOzwhkxM5aU7fMjJsb72JhD/OXwCMXYJ8t5/tMD+LD1+IXOLCAAAA[0m[Pipeline] { (clone)
[8mha:////4I3tKNYAz7At397ZkNOs6SFwEn2bzn3ZBhsoegW1dhRwAAAApB+LCAAAAAAAAP9tjTEOwjAQBC9BFLSUPOIiKpAQVVrLDS8wsTFOrDtjOyQVL+Jr/IFAJCq2WO1sM88XLFOEI0eLraHOUWocBt/baeHAsbt4HrDlMzZMib1BaQbJ2tQzSs4G5hQlLASsDDWekyObYS1adVeVV2SrU47TdxBQOn2DBxRiMmcV8xfGCJtrrxPTz/NXAGPIUG53n9qHNxXfVKy+AAAA[0m[Pipeline] sh
+ git clone -b develop https://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@github.com/intel-innersource/applications.validation.network-platform.npxtester.git npxtester
Cloning into 'npxtester'...
[8mha:////4CRWXV91kUhqh2bTVXI+2n5U32cQ89nJ7yub5blKQ29bAAAApB+LCAAAAAAAAP9tjTEOwjAQBC9BFLSUPOIiKoQQVVrLDS8wsTFOrDtjOyQVL+Jr/IFAJCq2WO1sM88XLFOEI0eLraHOUWocBt/baeHAsbt4HrDlMzZMib1BaQbJ2tQzSs4G5hQlLASsDDWekyObYS1adVeVV2SrU47TdxBQOn2DBxRiMmcV8xfGCJtrrxPTz/NXAGMIGcrt/lO7N9Jjga++AAAA[0m[Pipeline] }
[8mha:////4I4ZVrOFMvh2sVfxnfT9s6+paGHoH9OzkxEwdR4h+nRDAAAApR+LCAAAAAAAAP9tjTEOwjAQBC9BFLSUPOICFDQoFa3lhheYxBgn1l2wHZyKF/E1/oBFJCq2WO1sM683LIOHmr3BTlNvKTQWBzeavDCx76+OE3Z8wYYpsNModZLc6tOMkqOGOUUJCwErTY3jYMlEWItOPVTlFJnqHH3+jgJK297hCYXI5qh8/MLkYXMb28D08/wVwDQMEcr9Ntfu8AERGGHOvgAAAA==[0m[Pipeline] // stage
[8mha:////4J4BpfnRrLE6odVrNZGgZ11wIRy0HYHBalvcHAcD12j/AAAAph+LCAAAAAAAAP9tjTEOwjAQBM9BKWgpeYQjEB2iorXc8AITG+PEugv2haTiRXyNPxCIRMVWOyut5vmCMic4UPKycdgGzHWQXez91ORAqb1EGmRDZ1kTZopOajdosu44oyZ2MEcUsFCwdFhHygE9w0o15m6qaNBXJ07TtldQBHuDBwg1mdkk/sKYYH3tbSb8ef4KYOwYxI6h2G4+x/INji2eq8EAAAA=[0m[Pipeline] stage
[8mha:////4AgPhGmio4pMNzq5gItmuDxswb3P5dwyIofUIBdMXBTmAAAAph+LCAAAAAAAAP9tjTEOwjAUQ3+DOrAycohUdEVMrFEXThCaEJJG/7dJSjpxIq7GHWipxIQHy7ZkvdcbyhjgRMFwp7GzGFvLez+aOfFMobt5ytzRlbeEkbzmjc4NKX1ea0NJw6qCwUbAVmPrKVo0CXbCyYesvERTXVKYt6MAZtUATyjETE4ypG+ZAuzvo4qEP85fAEx9AlYfFquXZ/kBAsTc3cIAAAA=[0m[Pipeline] { (set args)
[8mha:////4G9dxluK5ut2lxdfo2JVi6OIov1ZH/881VUFzuPzanonAAAAox+LCAAAAAAAAP9tjTESwiAURH/iWNhaeggyE0vHypah8QSYIEKY/wkQSeWJvJp3EM2MlVvs7NvmPV+wjgGOFDSzCgeDsTPMu0mXxTKF4eooM0sX1hFGcooJlQX16rSgoKRgSVXDisNGYecoGtQJttzKu2ycRN2cUyjfgUNt+hEeUPFiTjKkL8wBdrepj4Q/z18BzD5B3baf2vs3w5BRkb4AAAA=[0m[Pipeline] sh
+ python /root/.jenkins/workspace/spr-test-nicIperfTcpGuestsStress/npxtester/conf/change_args.py '{"drive_info":{"drive_version":"4.18.0-369.el8.x86_64"},"dpdk_dir":"/opt/APP/utility/DPDK_install/dpdk-22.03","vm_image_conf":{"image1":"rvm1.img","image2":"rvm2.img","image3":"rhel84rt.img","image4":"rhel84rt2.img","image_dir":"/home/"},"sut_conf":{"host":"10.239.182.80","run_time":"600","pf1":"ens43f0","os":"RHEL","pf1_bandwidth":"100","kernel_type":"Gen"},"pkg_generator":{"host":"10.239.182.88","pf1":"ens785f0"}}'
[8mha:////4FhUQONKPXFSeOjFO92QKbtxv93cUzSuhB7hx3xoWX6KAAAApB+LCAAAAAAAAP9tjbEOwiAURV9rHFwd/QiaNG7GyZWw+AXYIkLJexSodPKL/DX/QbSJk3e4uecu5/mCdQxwpKCZVTgYjJ1h3k26LJYpDFdHmVm6sI4wklNMqCyoV6cFBSUFS6oaVhw2CjtH0aBOsOVW3mXjJOrmnEL5Dhxq04/wgIoXc5IhfWEOsLtNfST8ef4KYPY+Qd3uP9W+Ad3NsHm+AAAA[0m[Pipeline] }
[8mha:////4EpM1Tihe33kOTBucrClpdwMCq1FF6wGwTU/AEOZmYaNAAAApB+LCAAAAAAAAP9tjTEOwjAQBC9BFLSUPOIikKgQVVrLDS8wsTFOrDtjOyQVL+Jr/IFAJCq2WO1sM88XLFOEI0eLraHOUWocBt/baeHAsbt4HrDlMzZMib1BaQbJ2tQzSs4G5hQlLASsDDWekyObYS1adVeVV2SrU47TdxBQOn2DBxRiMmcV8xfGCJtrrxPTz/NXAGMIGcrd/lPbN8JP5Su+AAAA[0m[Pipeline] // stage
[8mha:////4JJk4NQMkVX21N+ktknOqKLQw+FD2VU/fvD8dhBPuambAAAApx+LCAAAAAAAAP9tjTEOwjAQBM9BKWgpeYQjIUSDqGgtN7zAxMY4se6CfSGpeBFf4w8EIlGx1c5Kq3m+oMwJDpS8bBy2AXMdZBd7PzU5UGovkQbZ0FnWhJmik9oNmqw7zqiJHcwRBSwULB3WkXJAz7BSjbmbKhr01YnTtO0VFMHe4AFCTWY2ib8wJlhfe5sJf56/Ahg7BrFlKDa7z7F8AzYdm7bBAAAA[0m[Pipeline] stage
[8mha:////4GToWcz1lEtttcc1F67+obVKf97ChyGWoNBgdNb8ln6iAAAAqB+LCAAAAAAAAP9tjTEOwjAUQ3+LOrAycohUYoABMXWNsnCC0ISQNvq//KS0EyfiatyBlkpMeLBsS9Z7vaGIDCdiJxqLrcdYe9GF3k1JDMTtNdAgGrqImjBSsELZQZGx1VIVJQuLshxWEtYW60DRo0uwkY1+6DJodOU58bQdJeTe3OEJmZzISXP6lpFhe+tNJPxx/gJg7BLku/1sh/lZfAAyQCqkwgAAAA==[0m[Pipeline] { (run nic case)
[8mha:////4Dqouna/UALz1cds/DYDIib12lRO4R4U9QQgmUx/wyv5AAAAqB+LCAAAAAAAAP9tjTEOwjAUQ3+LOrAycohUYgEJMXWNsnCC0ISQNvq//KS0EyfiatyBlkpMeLBsS9Z7vaGIDCdiJxqLrcdYe9GF3k1JDMTtNdAgGrqImjBSsELZQZGx1VIVJQuLshxWEtYW60DRo0uwkY1+6DJodOU58bQdJeTe3OEJmZzISXP6lpFhe+tNJPxx/gJg7BLku/1sh/lZfAAnLfKUwgAAAA==[0m[Pipeline] script
[8mha:////4JUhH4fIWh5icAEY6zBr3HRHHu0lnMalVyM2fPsu3/3sAAAApx+LCAAAAAAAAP9tjTEOwjAUQ3+LOrAycohUYgIhpq5RFk4QmhDSRv+Xn5R24kRcjTvQUokJD5ZtyXqvNxSR4UTsRGOx9RhrL7rQuymJgbi9BhpEQxdRE0YKVig7KDK2WqqiZGFRlsNKwtpiHSh6dAk2stEPXQaNrjwnnrajhNybOzwhkxM5aU7fMjJsb72JhD/OXwCMXYJ8t5/tMD+LD0QKVszCAAAA[0m[Pipeline] {
[8mha:////4PJRxj8hD/CuSHgtWDRwAQ67XTdBRcldvWih24U4ysBWAAAApR+LCAAAAAAAAP9tjTEOwjAQBC9BFLSUPOKCoEIoFa3lhheYxBgn1l2wHZyKF/E1/oBFJCq2WO1sM683LIOHmr3BTlNvKTQWBzeavDCx76+OE3Z8wYYpsNModZLc6tOMkqOGOUUJCwErTY3jYMlEWItOPVTlFJnqHH3+jgJK297hCYXI5qh8/MLkYXMb28D08/wVwDREKHeHXPvt8AHN/bm5vgAAAA==[0m[Pipeline] sh
+ pytest /root/.jenkins/workspace/spr-test-nicIperfTcpGuestsStress/npxtester/Tests/testNics -s -m nicIperfTcpGuestStress --capture=tee-sys --html=/root/testconfig/testlogs/HtmlReport/nicIperfTcpGuestStress_ipv4_report.html --self-contained-html
============================= test session starts ==============================
platform linux -- Python 3.6.8, pytest-6.2.4, py-1.11.0, pluggy-0.13.1
rootdir: /root/.jenkins/workspace/spr-test-nicIperfTcpGuestsStress/npxtester/Tests/testNics, configfile: pytest.ini
plugins: metadata-1.11.0, html-3.1.1
collected 20 items / 18 deselected / 2 selected

npxtester/Tests/testNics/test_network_sriov_stress.py 2022-04-26 18:22:08 - NicTestFixture.py - [line:27] - root - INFO - case_logpath: /root/testconfig/testlogs/2022-04-26/test_PI_Iperf_TCP_Stress_Guests[ipv4-rvm2.img-rvm1.img]_18_22_08/test_PI_Iperf_TCP_Stress_Guests[ipv4-rvm2.img-rvm1.img].log, case_logdir: /root/testconfig/testlogs/2022-04-26/test_PI_Iperf_TCP_Stress_Guests[ipv4-rvm2.img-rvm1.img]_18_22_08
2022-04-26 18:22:08 - NicTestFixture.py - [line:31] - root - INFO - ============================ Starting to run test_PI_Iperf_TCP_Stress_Guests[ipv4-rvm2.img-rvm1.img] case ============================
2022-04-26 18:22:08 - test_network_sriov_stress.py - [line:32] - root - INFO - SSH SUT and setup configurations in the setup function.
2022-04-26 18:22:08 - test_network_sriov_stress.py - [line:50] - root - INFO - ssh to the sut1
2022-04-26 18:22:08 - transport.py - [line:1819] - paramiko.transport - INFO - Connected (version 2.0, client OpenSSH_8.0)
2022-04-26 18:22:08 - transport.py - [line:1819] - paramiko.transport - INFO - Authentication (password) successful!
2022-04-26 18:22:08 - sshInstance.py - [line:28] - root - INFO - SSH on SUT: 10.239.182.80
2022-04-26 18:22:08 - transport.py - [line:1819] - paramiko.transport - INFO - Connected (version 2.0, client OpenSSH_8.0)
2022-04-26 18:22:09 - transport.py - [line:1819] - paramiko.transport - INFO - Authentication (password) successful!
2022-04-26 18:22:09 - sshInstance.py - [line:28] - root - INFO - SSH on SUT: 10.239.182.88
2022-04-26 18:22:09 - test_network_sriov_stress.py - [line:64] - root - INFO - clean up iperf and taskset process...
2022-04-26 18:22:12 - sshInstance.py - [line:50] - root - INFO - pkill -9 iperf
2022-04-26 18:22:12 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:22:20 - sshInstance.py - [line:50] - root - INFO - pkill -9 taskset
2022-04-26 18:22:20 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:22:28 - sshInstance.py - [line:50] - root - INFO - pkill -9 iperf
2022-04-26 18:22:28 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:22:36 - sshInstance.py - [line:50] - root - INFO - pkill -9 taskset
2022-04-26 18:22:36 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:22:41 - sftp.py - [line:158] - paramiko.transport.sftp - INFO - [chan 3] Opened sftp connection (server version 3)
2022-04-26 18:22:41 - sshInstance.py - [line:199] - root - INFO - start to rmmod irdma....
2022-04-26 18:22:44 - sshInstance.py - [line:50] - root - INFO - rmmod irdma
2022-04-26 18:22:44 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:22:49 - sshInstance.py - [line:202] - root - INFO - finished rmmod irdma....
2022-04-26 18:22:49 - sshInstance.py - [line:203] - root - INFO - start to rmmod ice....
2022-04-26 18:22:52 - sshInstance.py - [line:50] - root - INFO - rmmod ice
2022-04-26 18:23:03 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:23:08 - sshInstance.py - [line:206] - root - INFO - finished rmmod ice....
2022-04-26 18:23:08 - sshInstance.py - [line:208] - root - INFO - start to modprobe ice....
2022-04-26 18:23:11 - sshInstance.py - [line:50] - root - INFO - modprobe ice
2022-04-26 18:23:48 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:23:53 - sshInstance.py - [line:210] - root - INFO - finished modprobe ice....
2022-04-26 18:23:56 - sshInstance.py - [line:50] - root - INFO - ethtool -i ens43f0
2022-04-26 18:23:56 - sshInstance.py - [line:54] - root - INFO - driver: ice
version: 4.18.0-369.el8.x86_64
firmware-version: 3.10 0x8000ad67 1.3106.0
expansion-rom-version: 
bus-info: 0000:98:00.0
supports-statistics: yes
supports-test: yes
supports-eeprom-access: yes
supports-register-dump: yes
supports-priv-flags: yes

2022-04-26 18:24:01 - test_network_sriov_stress.py - [line:72] - root - INFO - try to get ipv6 of pf for redhat...
2022-04-26 18:24:01 - sshInstance.py - [line:187] - root - INFO - starting to delete network of ens43f0:
2022-04-26 18:24:07 - sshInstance.py - [line:99] - root - INFO - Activate the web console with: systemctl enable --now cockpit.socket
Register this system with Red Hat Insights: insights-client --register
Create an account or view all your systems at https://red.ht/insights-dashboard
Last login: Tue Apr 26 18:32:36 2022 from 10.112.97.60
[root@npx-auto-SPR-quanta ~]# nmcli connection delete ens43f0
Connection 'ens43f0' (6c0fc539-da39-434d-ae5c-22933ff59fb7) successfully deleted.
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:24:10 - sshInstance.py - [line:189] - root - INFO - restart networkManager to make setting valid
2022-04-26 18:24:16 - sshInstance.py - [line:99] - root - INFO - systemctl restart NetworkManager
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:24:19 - sshInstance.py - [line:192] - root - INFO - starting to add network of ens43f0:
2022-04-26 18:24:25 - sshInstance.py - [line:99] - root - INFO - nmcli connection add type ethernet con-name ens43f00 ifname ens43f0
Connection 'ens43f0' (75a108ed-a24b-47b9-81d0-185d4f47aa23) successfully added.
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:24:28 - sshInstance.py - [line:195] - root - INFO - restart networkManager to make setting valid
2022-04-26 18:24:34 - sshInstance.py - [line:99] - root - INFO - systemctl restart NetworkManager
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:24:37 - test_network_sriov_stress.py - [line:78] - root - INFO - try to get ipv6 for ens785f0
2022-04-26 18:24:37 - test_network_sriov_stress.py - [line:80] - root - INFO - getting ipv6 in redhat.
2022-04-26 18:24:37 - sshInstance.py - [line:187] - root - INFO - starting to delete network of ens785f0:
2022-04-26 18:24:43 - sshInstance.py - [line:99] - root - INFO - Activate the web console with: systemctl enable --now cockpit.socket
This system is not registered to Red Hat Insights. See https://cloud.redhat.com/
To register this system, run: insights-client --register
Last login: Tue Apr 26 18:33:19 2022 from 10.112.97.60
xhost:  unable to open display ""
[root@CYP10RT ~]# nmcli connection delete ens785f0
Connection 'ens785f0' (17a89cda-b40b-4935-a8c9-5d221e72d4c3) successfully deleted.
[root@CYP10RT ~]# 
2022-04-26 18:24:46 - sshInstance.py - [line:189] - root - INFO - restart networkManager to make setting valid
2022-04-26 18:24:52 - sshInstance.py - [line:99] - root - INFO - systemctl restart NetworkManager
[root@CYP10RT ~]# 
2022-04-26 18:24:55 - sshInstance.py - [line:192] - root - INFO - starting to add network of ens785f0:
2022-04-26 18:25:01 - sshInstance.py - [line:99] - root - INFO - nmcli connection add type ethernet con-name ens785f0 ifname enss785f0
Connection 'ens785f0' (dcd37f98-827d-4263-942c-ea2587552429) successfully added.
[root@CYP10RT ~]# 
2022-04-26 18:25:04 - sshInstance.py - [line:195] - root - INFO - restart networkManager to make setting valid
2022-04-26 18:25:10 - sshInstance.py - [line:99] - root - INFO - systemctl restart NetworkManager
[root@CYP10RT ~]# 
2022-04-26 18:25:13 - test_network_sriov_stress.py - [line:88] - root - INFO - trying to get ipv6 addr for pf1
2022-04-26 18:25:16 - sshInstance.py - [line:50] - root - INFO - ifconfig ens43f0
2022-04-26 18:25:16 - sshInstance.py - [line:54] - root - INFO - ens43f0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
        inet6 fe80::4ec8:ba5b:2f1c:85ba  prefixlen 64  scopeid 0x20<link>
        ether b4:96:91:a0:20:d8  txqueuelen 1000  (Ethernet)
        RX packets 0  bytes 0 (0.0 B)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 23  bytes 4256 (4.1 KiB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0


2022-04-26 18:25:24 - sshInstance.py - [line:50] - root - INFO - ifconfig ens785f0
2022-04-26 18:25:24 - sshInstance.py - [line:54] - root - INFO - ens785f0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
        inet6 fe80::6bad:883c:a61:3f8e  prefixlen 64  scopeid 0x20<link>
        ether b4:96:91:a0:21:70  txqueuelen 1000  (Ethernet)
        RX packets 27872973019  bytes 42172095226188 (38.3 TiB)
        RX errors 0  dropped 9838  overruns 0  frame 0
        TX packets 756505624  bytes 52161214759 (48.5 GiB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0


2022-04-26 18:25:32 - sshInstance.py - [line:50] - root - INFO - /opt/APP/utility/DPDK_install/dpdk-22.03/usertools/dpdk-devbind.py -s | grep ens43f0 | awk '{print $1;}'
2022-04-26 18:25:33 - sshInstance.py - [line:54] - root - INFO - 0000:98:00.0

2022-04-26 18:25:38 - test_network_sriov_stress.py - [line:139] - root - INFO - pf_id was found: 0000:98:00.0

2022-04-26 18:25:38 - test_network_sriov_stress.py - [line:979] - root - INFO - format_pf_id is 0000\:98\:00.0

2022-04-26 18:25:38 - test_network_sriov_stress.py - [line:982] - root - INFO - pf_id_key: 98
2022-04-26 18:25:38 - test_network_sriov_stress.py - [line:986] - root - INFO - assign sut1 pf ens43f0 ip
2022-04-26 18:25:44 - sshInstance.py - [line:99] - root - INFO - ifconfig ens43f0 192.168.10.10
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:25:47 - test_network_sriov_stress.py - [line:348] - root - INFO - Successfully assigned ip to ethernet: ens43f0
2022-04-26 18:25:47 - test_network_sriov_stress.py - [line:991] - root - INFO - assign sut2 pf ens785f0 ip
2022-04-26 18:25:53 - sshInstance.py - [line:99] - root - INFO - ifconfig ens785f0 192.168.10.11
[root@CYP10RT ~]# 
2022-04-26 18:25:56 - test_network_sriov_stress.py - [line:348] - root - INFO - Successfully assigned ip to ethernet: ens785f0
2022-04-26 18:25:56 - test_network_sriov_stress.py - [line:145] - root - INFO - virtulize sut1 pf to 4 vfs
2022-04-26 18:25:59 - sshInstance.py - [line:50] - root - INFO - echo 4 > /sys/class/net/ens43f0/device/sriov_numvfs
2022-04-26 18:26:03 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:26:08 - test_network_sriov_stress.py - [line:154] - root - INFO - Successfully Virtualized PF to VFs.
2022-04-26 18:26:11 - sshInstance.py - [line:50] - root - INFO - lspci | grep "Virtual" |grep 98 | awk '{print $1;}'list
2022-04-26 18:26:11 - sshInstance.py - [line:54] - root - INFO - 98:01.0
98:01.1
98:01.2
98:01.3

2022-04-26 18:26:16 - test_network_sriov_stress.py - [line:168] - root - INFO - Succssfully Gotten vf_id list:

2022-04-26 18:26:19 - sshInstance.py - [line:50] - root - INFO - modprobe vfio-pci

2022-04-26 18:26:19 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:26:24 - test_network_sriov_stress.py - [line:188] - root - INFO - start to bind drive in sut1
2022-04-26 18:26:27 - sshInstance.py - [line:50] - root - INFO - /opt/APP/utility/DPDK_install/dpdk-22.03/usertools/dpdk-devbind.py -b vfio-pci 98:01.0
2022-04-26 18:26:30 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:26:35 - test_network_sriov_stress.py - [line:202] - root - INFO - Successfuly bound VF to vfio-pci
2022-04-26 18:26:38 - sshInstance.py - [line:50] - root - INFO - /opt/APP/utility/DPDK_install/dpdk-22.03/usertools/dpdk-devbind.py -b vfio-pci 98:01.1
2022-04-26 18:26:40 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:26:45 - test_network_sriov_stress.py - [line:202] - root - INFO - Successfuly bound VF to vfio-pci
2022-04-26 18:26:45 - test_network_sriov_stress.py - [line:1011] - root - INFO - Start get vf device id in sut1
2022-04-26 18:26:45 - test_network_sriov_stress.py - [line:1013] - root - INFO - lspci -Dnn | grep 98:01.1
2022-04-26 18:26:48 - sshInstance.py - [line:50] - root - INFO - lspci -Dnn | grep 98:01.1
2022-04-26 18:26:48 - sshInstance.py - [line:54] - root - INFO - 0000:98:01.1 Ethernet controller [0200]: Intel Corporation Ethernet Adaptive Virtual Function [8086:1889] (rev 02)

2022-04-26 18:26:53 - test_network_sriov_stress.py - [line:1027] - root - INFO - Successfully get vf device id: 8086:1889
2022-04-26 18:26:53 - test_network_sriov_stress.py - [line:225] - root - INFO - get default network info: virsh net-info default | grep "Active" | awk '{print $2;}'
2022-04-26 18:26:56 - sshInstance.py - [line:50] - root - INFO - virsh net-info default | grep "Active" | awk '{print $2;}'
2022-04-26 18:26:57 - sshInstance.py - [line:54] - root - INFO - yes

2022-04-26 18:27:02 - test_network_sriov_stress.py - [line:228] - root - INFO - Default network is active? yes

2022-04-26 18:27:02 - test_network_sriov_stress.py - [line:1036] - root - INFO - Start create VM in sut1
2022-04-26 18:27:02 - test_network_sriov_stress.py - [line:258] - root - INFO - try to create VM with the cmd1: virt-install --name VMtest1 --ram 4096 --cpu host --vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk path=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=0.0.0.0,port=5900 --noautoconsole

2022-04-26 18:27:06 - sshInstance.py - [line:75] - root - INFO - virt-install --name VMtest1 --ram 4096 --cpu host ---vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk ppath=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=00.0.0.0,port=5900 --noautoconsole
2022-04-26 18:27:08 - sshInstance.py - [line:75] - root - INFO - ERROR    Disk /home/rvm2.img is already in use by other guests ['VMtest2']. (Use --check path_in_use=off or --check all=off to override)
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:27:14 - sshInstance.py - [line:50] - root - INFO - virsh list --all
2022-04-26 18:27:14 - sshInstance.py - [line:54] - root - INFO -  Id   Name      State
--------------------------
 -    VMtest1   shut off
 -    VMtest2   shut off


2022-04-26 18:27:19 - test_network_sriov_stress.py - [line:271] - root - INFO - Failed to create a VM: virt-install --name VMtest1 --ram 4096 --cpu host ---vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk ppath=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=00.0.0.0,port=5900 --noautoconsole
ERROR    Disk /home/rvm2.img is already in use by other guests ['VMtest2']. (Use --check path_in_use=off or --check all=off to override)
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:27:19 - test_network_sriov_stress.py - [line:272] - root - INFO - Failed to create a VM: 
2022-04-26 18:27:19 - test_network_sriov_stress.py - [line:258] - root - INFO - try to create VM with the cmd1: virt-install --name VMtest1 --ram 4096 --cpu host --vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk path=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=0.0.0.0,port=5900 --noautoconsole

2022-04-26 18:27:23 - sshInstance.py - [line:75] - root - INFO - virt-install --name VMtest1 --ram 4096 --cpu host ---vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk ppath=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=00.0.0.0,port=5900 --noautoconsole
2022-04-26 18:27:25 - sshInstance.py - [line:75] - root - INFO - ERROR    Disk /home/rvm2.img is already in use by other guests ['VMtest2']. (Use --check path_in_use=off or --check all=off to override)
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:27:31 - sshInstance.py - [line:50] - root - INFO - virsh list --all
2022-04-26 18:27:31 - sshInstance.py - [line:54] - root - INFO -  Id   Name      State
--------------------------
 -    VMtest1   shut off
 -    VMtest2   shut off


2022-04-26 18:27:36 - test_network_sriov_stress.py - [line:271] - root - INFO - Failed to create a VM: virt-install --name VMtest1 --ram 4096 --cpu host ---vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk ppath=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=00.0.0.0,port=5900 --noautoconsole
ERROR    Disk /home/rvm2.img is already in use by other guests ['VMtest2']. (Use --check path_in_use=off or --check all=off to override)
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:27:36 - test_network_sriov_stress.py - [line:272] - root - INFO - Failed to create a VM: 
2022-04-26 18:27:36 - test_network_sriov_stress.py - [line:258] - root - INFO - try to create VM with the cmd1: virt-install --name VMtest1 --ram 4096 --cpu host --vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk path=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=0.0.0.0,port=5900 --noautoconsole

2022-04-26 18:27:40 - sshInstance.py - [line:75] - root - INFO - virt-install --name VMtest1 --ram 4096 --cpu host ---vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk ppath=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=00.0.0.0,port=5900 --noautoconsole
2022-04-26 18:27:42 - sshInstance.py - [line:75] - root - INFO - ERROR    Disk /home/rvm2.img is already in use by other guests ['VMtest2']. (Use --check path_in_use=off or --check all=off to override)
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:27:48 - sshInstance.py - [line:50] - root - INFO - virsh list --all
2022-04-26 18:27:48 - sshInstance.py - [line:54] - root - INFO -  Id   Name      State
--------------------------
 -    VMtest1   shut off
 -    VMtest2   shut off


2022-04-26 18:27:53 - test_network_sriov_stress.py - [line:271] - root - INFO - Failed to create a VM: virt-install --name VMtest1 --ram 4096 --cpu host ---vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk ppath=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=00.0.0.0,port=5900 --noautoconsole
ERROR    Disk /home/rvm2.img is already in use by other guests ['VMtest2']. (Use --check path_in_use=off or --check all=off to override)
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:27:53 - test_network_sriov_stress.py - [line:272] - root - INFO - Failed to create a VM: 
2022-04-26 18:27:53 - test_network_sriov_stress.py - [line:280] - root - ERROR - Failed to create a VM: VMtest1)
F2022-04-26 18:27:53 - test_network_sriov_stress.py - [line:100] - root - INFO - removing VMs: VMtest1, VMtest2
2022-04-26 18:27:56 - sshInstance.py - [line:50] - root - INFO - virsh destroy VMtest2
2022-04-26 18:27:56 - sshInstance.py - [line:54] - root - INFO - error: Failed to destroy domain 'VMtest2'
error: Requested operation is not valid: domain is not running


2022-04-26 18:28:01 - test_network_sriov_stress.py - [line:325] - root - ERROR - Failed to shut down the VM VMtest2
2022-04-26 18:28:04 - sshInstance.py - [line:50] - root - INFO - virsh destroy VMtest1
2022-04-26 18:28:04 - sshInstance.py - [line:54] - root - INFO - error: Failed to destroy domain 'VMtest1'
error: Requested operation is not valid: domain is not running


2022-04-26 18:28:09 - test_network_sriov_stress.py - [line:325] - root - ERROR - Failed to shut down the VM VMtest1
2022-04-26 18:28:12 - sshInstance.py - [line:50] - root - INFO - echo 0 > /sys/class/net/ens43f0/device/sriov_numvfs
2022-04-26 18:28:18 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:28:26 - sshInstance.py - [line:50] - root - INFO - ifconfig ens43f0 0
2022-04-26 18:28:26 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:28:34 - sshInstance.py - [line:50] - root - INFO - ifconfig ens785f0 0
2022-04-26 18:28:34 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:28:42 - sshInstance.py - [line:50] - root - INFO - dmesg > /tmp/dmesg.log
2022-04-26 18:28:42 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:28:47 - test_network_sriov_stress.py - [line:109] - root - INFO - generate dmesg.log file on sut /tmp/dmesg.log
2022-04-26 18:28:47 - test_network_sriov_stress.py - [line:111] - root - INFO - copy dmesg.log from sut1 /tmp dir to controller dir /root/testconfig/testlogs/2022-04-26/test_PI_Iperf_TCP_Stress_Guests[ipv4-rvm2.img-rvm1.img]_18_22_08
2022-04-26 18:28:50 - sshInstance.py - [line:50] - root - INFO - rm -f /tmp/dmesg.log
2022-04-26 18:28:50 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:28:55 - test_network_sriov_stress.py - [line:113] - root - INFO - rm dmesg.log on sut1 /tmp dir
2022-04-26 18:28:58 - sshInstance.py - [line:50] - root - INFO - rm -f /tmp/*.txt
2022-04-26 18:28:58 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:29:03 - sshInstance.py - [line:43] - root - INFO - closing ssh client on SUT
2022-04-26 18:29:03 - NicTestFixture.py - [line:35] - root - INFO - ============================ end of run test_PI_Iperf_TCP_Stress_Guests[ipv4-rvm2.img-rvm1.img] case ============================
2022-04-26 18:29:03 - NicTestFixture.py - [line:27] - root - INFO - case_logpath: /root/testconfig/testlogs/2022-04-26/test_PI_Iperf_TCP_Stress_Guests[ipv6-rvm2.img-rvm1.img]_18_29_03/test_PI_Iperf_TCP_Stress_Guests[ipv6-rvm2.img-rvm1.img].log, case_logdir: /root/testconfig/testlogs/2022-04-26/test_PI_Iperf_TCP_Stress_Guests[ipv6-rvm2.img-rvm1.img]_18_29_03
2022-04-26 18:29:03 - NicTestFixture.py - [line:31] - root - INFO - ============================ Starting to run test_PI_Iperf_TCP_Stress_Guests[ipv6-rvm2.img-rvm1.img] case ============================
2022-04-26 18:29:03 - test_network_sriov_stress.py - [line:32] - root - INFO - SSH SUT and setup configurations in the setup function.
2022-04-26 18:29:03 - test_network_sriov_stress.py - [line:50] - root - INFO - ssh to the sut1
2022-04-26 18:29:03 - transport.py - [line:1819] - paramiko.transport - INFO - Connected (version 2.0, client OpenSSH_8.0)
2022-04-26 18:29:03 - transport.py - [line:1819] - paramiko.transport - INFO - Authentication (password) successful!
2022-04-26 18:29:03 - sshInstance.py - [line:28] - root - INFO - SSH on SUT: 10.239.182.80
2022-04-26 18:29:03 - transport.py - [line:1819] - paramiko.transport - INFO - Connected (version 2.0, client OpenSSH_8.0)
2022-04-26 18:29:04 - transport.py - [line:1819] - paramiko.transport - INFO - Authentication (password) successful!
2022-04-26 18:29:04 - sshInstance.py - [line:28] - root - INFO - SSH on SUT: 10.239.182.88
2022-04-26 18:29:04 - test_network_sriov_stress.py - [line:64] - root - INFO - clean up iperf and taskset process...
2022-04-26 18:29:07 - sshInstance.py - [line:50] - root - INFO - pkill -9 iperf
2022-04-26 18:29:07 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:29:15 - sshInstance.py - [line:50] - root - INFO - pkill -9 taskset
2022-04-26 18:29:15 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:29:23 - sshInstance.py - [line:50] - root - INFO - pkill -9 iperf
2022-04-26 18:29:23 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:29:31 - sshInstance.py - [line:50] - root - INFO - pkill -9 taskset
2022-04-26 18:29:31 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:29:36 - sftp.py - [line:158] - paramiko.transport.sftp - INFO - [chan 3] Opened sftp connection (server version 3)
2022-04-26 18:29:36 - sshInstance.py - [line:199] - root - INFO - start to rmmod irdma....
2022-04-26 18:29:39 - sshInstance.py - [line:50] - root - INFO - rmmod irdma
2022-04-26 18:29:39 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:29:44 - sshInstance.py - [line:202] - root - INFO - finished rmmod irdma....
2022-04-26 18:29:44 - sshInstance.py - [line:203] - root - INFO - start to rmmod ice....
2022-04-26 18:29:47 - sshInstance.py - [line:50] - root - INFO - rmmod ice
2022-04-26 18:29:58 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:30:03 - sshInstance.py - [line:206] - root - INFO - finished rmmod ice....
2022-04-26 18:30:03 - sshInstance.py - [line:208] - root - INFO - start to modprobe ice....
2022-04-26 18:30:06 - sshInstance.py - [line:50] - root - INFO - modprobe ice
2022-04-26 18:30:43 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:30:48 - sshInstance.py - [line:210] - root - INFO - finished modprobe ice....
2022-04-26 18:30:51 - sshInstance.py - [line:50] - root - INFO - ethtool -i ens43f0
2022-04-26 18:30:51 - sshInstance.py - [line:54] - root - INFO - driver: ice
version: 4.18.0-369.el8.x86_64
firmware-version: 3.10 0x8000ad67 1.3106.0
expansion-rom-version: 
bus-info: 0000:98:00.0
supports-statistics: yes
supports-test: yes
supports-eeprom-access: yes
supports-register-dump: yes
supports-priv-flags: yes

2022-04-26 18:30:56 - test_network_sriov_stress.py - [line:72] - root - INFO - try to get ipv6 of pf for redhat...
2022-04-26 18:30:56 - sshInstance.py - [line:187] - root - INFO - starting to delete network of ens43f0:
2022-04-26 18:31:02 - sshInstance.py - [line:99] - root - INFO - Activate the web console with: systemctl enable --now cockpit.socket
Register this system with Red Hat Insights: insights-client --register
Create an account or view all your systems at https://red.ht/insights-dashboard
Last login: Tue Apr 26 18:39:40 2022 from 10.112.97.60
[root@npx-auto-SPR-quanta ~]# nmcli connection delete ens43f0
Connection 'ens43f0' (75a108ed-a24b-47b9-81d0-185d4f47aa23) successfully deleted.
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:31:05 - sshInstance.py - [line:189] - root - INFO - restart networkManager to make setting valid
2022-04-26 18:31:11 - sshInstance.py - [line:99] - root - INFO - systemctl restart NetworkManager
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:31:14 - sshInstance.py - [line:192] - root - INFO - starting to add network of ens43f0:
2022-04-26 18:31:20 - sshInstance.py - [line:99] - root - INFO - nmcli connection add type ethernet con-name ens43f00 ifname ens43f0
Connection 'ens43f0' (dd4fc487-f122-4c64-8488-54069f402b18) successfully added.
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:31:23 - sshInstance.py - [line:195] - root - INFO - restart networkManager to make setting valid
2022-04-26 18:31:29 - sshInstance.py - [line:99] - root - INFO - systemctl restart NetworkManager
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:31:32 - test_network_sriov_stress.py - [line:78] - root - INFO - try to get ipv6 for ens785f0
2022-04-26 18:31:32 - test_network_sriov_stress.py - [line:80] - root - INFO - getting ipv6 in redhat.
2022-04-26 18:31:32 - sshInstance.py - [line:187] - root - INFO - starting to delete network of ens785f0:
2022-04-26 18:31:38 - sshInstance.py - [line:99] - root - INFO - Activate the web console with: systemctl enable --now cockpit.socket
This system is not registered to Red Hat Insights. See https://cloud.redhat.com/
To register this system, run: insights-client --register
Last login: Tue Apr 26 18:39:50 2022 from 10.112.97.60
xhost:  unable to open display ""
[root@CYP10RT ~]# nmcli connection delete ens785f0
Connection 'ens785f0' (dcd37f98-827d-4263-942c-ea2587552429) successfully deleted.
[root@CYP10RT ~]# 
2022-04-26 18:31:41 - sshInstance.py - [line:189] - root - INFO - restart networkManager to make setting valid
2022-04-26 18:31:47 - sshInstance.py - [line:99] - root - INFO - systemctl restart NetworkManager
[root@CYP10RT ~]# 
2022-04-26 18:31:50 - sshInstance.py - [line:192] - root - INFO - starting to add network of ens785f0:
2022-04-26 18:31:56 - sshInstance.py - [line:99] - root - INFO - nmcli connection add type ethernet con-name ens785f0 ifname enss785f0
Connection 'ens785f0' (d75d3875-920d-4e35-9eef-d354e1b6d096) successfully added.
[root@CYP10RT ~]# 
2022-04-26 18:31:59 - sshInstance.py - [line:195] - root - INFO - restart networkManager to make setting valid
2022-04-26 18:32:05 - sshInstance.py - [line:99] - root - INFO - systemctl restart NetworkManager
[root@CYP10RT ~]# 
2022-04-26 18:32:08 - test_network_sriov_stress.py - [line:88] - root - INFO - trying to get ipv6 addr for pf1
2022-04-26 18:32:11 - sshInstance.py - [line:50] - root - INFO - ifconfig ens43f0
2022-04-26 18:32:11 - sshInstance.py - [line:54] - root - INFO - ens43f0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
        inet6 fe80::7b6c:ccd1:eb3a:b437  prefixlen 64  scopeid 0x20<link>
        ether b4:96:91:a0:20:d8  txqueuelen 1000  (Ethernet)
        RX packets 0  bytes 0 (0.0 B)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 40  bytes 7040 (6.8 KiB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0


2022-04-26 18:32:19 - sshInstance.py - [line:50] - root - INFO - ifconfig ens785f0
2022-04-26 18:32:19 - sshInstance.py - [line:54] - root - INFO - ens785f0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
        inet6 fe80::62bb:eabe:e877:807b  prefixlen 64  scopeid 0x20<link>
        ether b4:96:91:a0:21:70  txqueuelen 1000  (Ethernet)
        RX packets 27872973019  bytes 42172095226188 (38.3 TiB)
        RX errors 0  dropped 9838  overruns 0  frame 0
        TX packets 756505678  bytes 52161225973 (48.5 GiB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0


2022-04-26 18:32:27 - sshInstance.py - [line:50] - root - INFO - /opt/APP/utility/DPDK_install/dpdk-22.03/usertools/dpdk-devbind.py -s | grep ens43f0 | awk '{print $1;}'
2022-04-26 18:32:28 - sshInstance.py - [line:54] - root - INFO - 0000:98:00.0

2022-04-26 18:32:33 - test_network_sriov_stress.py - [line:139] - root - INFO - pf_id was found: 0000:98:00.0

2022-04-26 18:32:33 - test_network_sriov_stress.py - [line:979] - root - INFO - format_pf_id is 0000\:98\:00.0

2022-04-26 18:32:33 - test_network_sriov_stress.py - [line:982] - root - INFO - pf_id_key: 98
2022-04-26 18:32:33 - test_network_sriov_stress.py - [line:986] - root - INFO - assign sut1 pf ens43f0 ip
2022-04-26 18:32:39 - sshInstance.py - [line:99] - root - INFO - ifconfig ens43f0 192.168.10.10
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:32:42 - test_network_sriov_stress.py - [line:348] - root - INFO - Successfully assigned ip to ethernet: ens43f0
2022-04-26 18:32:42 - test_network_sriov_stress.py - [line:991] - root - INFO - assign sut2 pf ens785f0 ip
2022-04-26 18:32:48 - sshInstance.py - [line:99] - root - INFO - ifconfig ens785f0 192.168.10.11
[root@CYP10RT ~]# 
2022-04-26 18:32:51 - test_network_sriov_stress.py - [line:348] - root - INFO - Successfully assigned ip to ethernet: ens785f0
2022-04-26 18:32:51 - test_network_sriov_stress.py - [line:145] - root - INFO - virtulize sut1 pf to 4 vfs
2022-04-26 18:32:54 - sshInstance.py - [line:50] - root - INFO - echo 4 > /sys/class/net/ens43f0/device/sriov_numvfs
2022-04-26 18:32:59 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:33:04 - test_network_sriov_stress.py - [line:154] - root - INFO - Successfully Virtualized PF to VFs.
2022-04-26 18:33:07 - sshInstance.py - [line:50] - root - INFO - lspci | grep "Virtual" |grep 98 | awk '{print $1;}'list
2022-04-26 18:33:07 - sshInstance.py - [line:54] - root - INFO - 98:01.0
98:01.1
98:01.2
98:01.3

2022-04-26 18:33:12 - test_network_sriov_stress.py - [line:168] - root - INFO - Succssfully Gotten vf_id list:

2022-04-26 18:33:15 - sshInstance.py - [line:50] - root - INFO - modprobe vfio-pci

2022-04-26 18:33:15 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:33:20 - test_network_sriov_stress.py - [line:188] - root - INFO - start to bind drive in sut1
2022-04-26 18:33:23 - sshInstance.py - [line:50] - root - INFO - /opt/APP/utility/DPDK_install/dpdk-22.03/usertools/dpdk-devbind.py -b vfio-pci 98:01.0
2022-04-26 18:33:25 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:33:30 - test_network_sriov_stress.py - [line:202] - root - INFO - Successfuly bound VF to vfio-pci
2022-04-26 18:33:33 - sshInstance.py - [line:50] - root - INFO - /opt/APP/utility/DPDK_install/dpdk-22.03/usertools/dpdk-devbind.py -b vfio-pci 98:01.1
2022-04-26 18:33:36 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:33:41 - test_network_sriov_stress.py - [line:202] - root - INFO - Successfuly bound VF to vfio-pci
2022-04-26 18:33:41 - test_network_sriov_stress.py - [line:1011] - root - INFO - Start get vf device id in sut1
2022-04-26 18:33:41 - test_network_sriov_stress.py - [line:1013] - root - INFO - lspci -Dnn | grep 98:01.1
2022-04-26 18:33:44 - sshInstance.py - [line:50] - root - INFO - lspci -Dnn | grep 98:01.1
2022-04-26 18:33:44 - sshInstance.py - [line:54] - root - INFO - 0000:98:01.1 Ethernet controller [0200]: Intel Corporation Ethernet Adaptive Virtual Function [8086:1889] (rev 02)

2022-04-26 18:33:49 - test_network_sriov_stress.py - [line:1027] - root - INFO - Successfully get vf device id: 8086:1889
2022-04-26 18:33:49 - test_network_sriov_stress.py - [line:225] - root - INFO - get default network info: virsh net-info default | grep "Active" | awk '{print $2;}'
2022-04-26 18:33:52 - sshInstance.py - [line:50] - root - INFO - virsh net-info default | grep "Active" | awk '{print $2;}'
2022-04-26 18:33:53 - sshInstance.py - [line:54] - root - INFO - yes

2022-04-26 18:33:58 - test_network_sriov_stress.py - [line:228] - root - INFO - Default network is active? yes

2022-04-26 18:33:58 - test_network_sriov_stress.py - [line:1036] - root - INFO - Start create VM in sut1
2022-04-26 18:33:58 - test_network_sriov_stress.py - [line:258] - root - INFO - try to create VM with the cmd1: virt-install --name VMtest1 --ram 4096 --cpu host --vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk path=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=0.0.0.0,port=5900 --noautoconsole

2022-04-26 18:34:02 - sshInstance.py - [line:75] - root - INFO - virt-install --name VMtest1 --ram 4096 --cpu host ---vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk ppath=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=00.0.0.0,port=5900 --noautoconsole
2022-04-26 18:34:04 - sshInstance.py - [line:75] - root - INFO - ERROR    Disk /home/rvm2.img is already in use by other guests ['VMtest2']. (Use --check path_in_use=off or --check all=off to override)
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:34:10 - sshInstance.py - [line:50] - root - INFO - virsh list --all
2022-04-26 18:34:10 - sshInstance.py - [line:54] - root - INFO -  Id   Name      State
--------------------------
 -    VMtest1   shut off
 -    VMtest2   shut off


2022-04-26 18:34:15 - test_network_sriov_stress.py - [line:271] - root - INFO - Failed to create a VM: virt-install --name VMtest1 --ram 4096 --cpu host ---vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk ppath=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=00.0.0.0,port=5900 --noautoconsole
ERROR    Disk /home/rvm2.img is already in use by other guests ['VMtest2']. (Use --check path_in_use=off or --check all=off to override)
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:34:15 - test_network_sriov_stress.py - [line:272] - root - INFO - Failed to create a VM: 
2022-04-26 18:34:15 - test_network_sriov_stress.py - [line:258] - root - INFO - try to create VM with the cmd1: virt-install --name VMtest1 --ram 4096 --cpu host --vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk path=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=0.0.0.0,port=5900 --noautoconsole

2022-04-26 18:34:19 - sshInstance.py - [line:75] - root - INFO - virt-install --name VMtest1 --ram 4096 --cpu host ---vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk ppath=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=00.0.0.0,port=5900 --noautoconsole
2022-04-26 18:34:21 - sshInstance.py - [line:75] - root - INFO - ERROR    Disk /home/rvm2.img is already in use by other guests ['VMtest2']. (Use --check path_in_use=off or --check all=off to override)
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:34:27 - sshInstance.py - [line:50] - root - INFO - virsh list --all
2022-04-26 18:34:27 - sshInstance.py - [line:54] - root - INFO -  Id   Name      State
--------------------------
 -    VMtest1   shut off
 -    VMtest2   shut off


2022-04-26 18:34:32 - test_network_sriov_stress.py - [line:271] - root - INFO - Failed to create a VM: virt-install --name VMtest1 --ram 4096 --cpu host ---vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk ppath=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=00.0.0.0,port=5900 --noautoconsole
ERROR    Disk /home/rvm2.img is already in use by other guests ['VMtest2']. (Use --check path_in_use=off or --check all=off to override)
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:34:32 - test_network_sriov_stress.py - [line:272] - root - INFO - Failed to create a VM: 
2022-04-26 18:34:32 - test_network_sriov_stress.py - [line:258] - root - INFO - try to create VM with the cmd1: virt-install --name VMtest1 --ram 4096 --cpu host --vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk path=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=0.0.0.0,port=5900 --noautoconsole

2022-04-26 18:34:36 - sshInstance.py - [line:75] - root - INFO - virt-install --name VMtest1 --ram 4096 --cpu host ---vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk ppath=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=00.0.0.0,port=5900 --noautoconsole
2022-04-26 18:34:38 - sshInstance.py - [line:75] - root - INFO - ERROR    Disk /home/rvm2.img is already in use by other guests ['VMtest2']. (Use --check path_in_use=off or --check all=off to override)
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:34:44 - sshInstance.py - [line:50] - root - INFO - virsh list --all
2022-04-26 18:34:44 - sshInstance.py - [line:54] - root - INFO -  Id   Name      State
--------------------------
 -    VMtest1   shut off
 -    VMtest2   shut off


2022-04-26 18:34:49 - test_network_sriov_stress.py - [line:271] - root - INFO - Failed to create a VM: virt-install --name VMtest1 --ram 4096 --cpu host ---vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk ppath=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=00.0.0.0,port=5900 --noautoconsole
ERROR    Disk /home/rvm2.img is already in use by other guests ['VMtest2']. (Use --check path_in_use=off or --check all=off to override)
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:34:49 - test_network_sriov_stress.py - [line:272] - root - INFO - Failed to create a VM: 
2022-04-26 18:34:49 - test_network_sriov_stress.py - [line:280] - root - ERROR - Failed to create a VM: VMtest1)
F2022-04-26 18:34:49 - test_network_sriov_stress.py - [line:100] - root - INFO - removing VMs: VMtest1, VMtest2
2022-04-26 18:34:52 - sshInstance.py - [line:50] - root - INFO - virsh destroy VMtest2
2022-04-26 18:34:52 - sshInstance.py - [line:54] - root - INFO - error: Failed to destroy domain 'VMtest2'
error: Requested operation is not valid: domain is not running


2022-04-26 18:34:57 - test_network_sriov_stress.py - [line:325] - root - ERROR - Failed to shut down the VM VMtest2
2022-04-26 18:35:00 - sshInstance.py - [line:50] - root - INFO - virsh destroy VMtest1
2022-04-26 18:35:00 - sshInstance.py - [line:54] - root - INFO - error: Failed to destroy domain 'VMtest1'
error: Requested operation is not valid: domain is not running


2022-04-26 18:35:05 - test_network_sriov_stress.py - [line:325] - root - ERROR - Failed to shut down the VM VMtest1
2022-04-26 18:35:08 - sshInstance.py - [line:50] - root - INFO - echo 0 > /sys/class/net/ens43f0/device/sriov_numvfs
2022-04-26 18:35:14 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:35:22 - sshInstance.py - [line:50] - root - INFO - ifconfig ens43f0 0
2022-04-26 18:35:22 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:35:30 - sshInstance.py - [line:50] - root - INFO - ifconfig ens785f0 0
2022-04-26 18:35:30 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:35:38 - sshInstance.py - [line:50] - root - INFO - dmesg > /tmp/dmesg.log
2022-04-26 18:35:38 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:35:43 - test_network_sriov_stress.py - [line:109] - root - INFO - generate dmesg.log file on sut /tmp/dmesg.log
2022-04-26 18:35:43 - test_network_sriov_stress.py - [line:111] - root - INFO - copy dmesg.log from sut1 /tmp dir to controller dir /root/testconfig/testlogs/2022-04-26/test_PI_Iperf_TCP_Stress_Guests[ipv6-rvm2.img-rvm1.img]_18_29_03
2022-04-26 18:35:46 - sshInstance.py - [line:50] - root - INFO - rm -f /tmp/dmesg.log
2022-04-26 18:35:46 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:35:51 - test_network_sriov_stress.py - [line:113] - root - INFO - rm dmesg.log on sut1 /tmp dir
2022-04-26 18:35:54 - sshInstance.py - [line:50] - root - INFO - rm -f /tmp/*.txt
2022-04-26 18:35:54 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:35:59 - sshInstance.py - [line:43] - root - INFO - closing ssh client on SUT
2022-04-26 18:35:59 - NicTestFixture.py - [line:35] - root - INFO - ============================ end of run test_PI_Iperf_TCP_Stress_Guests[ipv6-rvm2.img-rvm1.img] case ============================
                 [100%]

=================================== FAILURES ===================================
_ Test_Network_SRIOV_Stress.test_PI_Iperf_TCP_Stress_Guests[ipv4-rvm2.img-rvm1.img] _

self = <Tests.testNics.test_network_sriov_stress.Test_Network_SRIOV_Stress object at 0x7f2d70255470>
vm1_image = 'rvm2.img', vm2_image = 'rvm1.img', ip_type = 'ipv4'

    @pytest.mark.usefixtures("fbefore")
    @pytest.mark.nicAll
    @pytest.mark.nicStress
    @pytest.mark.nicIperfTcpGuestStress
    @pytest.mark.SriovVfIperf
    @pytest.mark.parametrize('vm1_image, vm2_image,', vm_image)
    @pytest.mark.parametrize('ip_type', run_type)
    def test_PI_Iperf_TCP_Stress_Guests(self, vm1_image, vm2_image, ip_type):
        iperf_log_name = "iperf_vm1_vm2_2hours.txt"
        # run_type = settings.__getattribute__("run_type")
        pf_id, status = self.get_pf_id(self.client, self.pf_name)
        # transfer pf_id to 0000\:00\:00.0 format
        if not pf_id:
            assert 200 == status
        else:
            pf_id_format = pf_id.replace(":", "\\:", 2)
            logging.info("format_pf_id is {}".format(pf_id_format))
            # get the number key of pf_id
            pf_id_key = pf_id.split(":")[1]
            logging.info("pf_id_key: {}".format(pf_id_key))
            # assign IP to PF in SUT and sut2
            sut1_pf_ip = "192.168.10.10"
            sut2_pf_ip = "192.168.10.11"
            logging.info("assign sut1 pf {} ip".format(self.pf_name))
            st = self.assign_ip_ehternet(self.session, sut1_pf_ip, self.pf_name)
            if st != 200:
                logging.error("Fail to assign sut1 pf {} failed".format(self.pf_name))
                assert 200 == 400, "Fail to assign sut1 pf {} failed"
            logging.info("assign sut2 pf {} ip".format(self.pf2_name))
            st = self.assign_ip_ehternet(self.session2, sut2_pf_ip, self.pf2_name)
            if st !=200:
                logging.error("Fail to assign sut2 pf {} ".format(self.pf2_name))
                assert 200 == 400, "Fail to assign sut1 pf {}"
    
            # virtulize the pf to vfs
            assert 200 == self.virtualize_pf_to_vfs(self.pf_name)
            # get vf ids
            vf_id_list, status = self.get_vf_ids(self.client, pf_id_key)
            vf_id_list = [i.strip() for i in vf_id_list]
            if status == 200:
                # modprobe vfio-pci
                assert 200 == self.modprobe("vfio-pci")
                # bind vf with vfio-pci
                host_dev_id_list, status = self.bind_vf_to_vfio_pci(self.client, vf_id_list)
                assert 200 == status
            else:
                assert 200 == status
            # get vF device id
            logging.info("Start get vf device id in sut1")
            cmd = "lspci -Dnn | grep %s" % (vf_id_list[1])
            logging.info(cmd)
            vf_device_id = ""
            vf_device_id_rs, error = self.ssh_sut.ssh_exec_cmd(self.client, cmd)
            vf_device_id_rs = vf_device_id_rs.strip()
            if vf_device_id_rs:
                st = False
                vf_device_id = None
                for one in vf_device_id_rs.split(" "):
                    one = " " + one + " "
                    if one.find(" [") > -1 and one.find("] ") > -1 and one.find(":") > -1:
                        vf_device_id = one.replace("[", "").replace("]", "").strip()
                if not vf_device_id:
                    logging.error("Fail to get vf_device_id")
                    assert 200 == 400, "vf_device_id is not found"
                logging.info("Successfully get vf device id: {}".format(vf_device_id))
            else:
                logging.error("Fail to get vf device id.")
                assert 200 == 400
            # set network
            status = self.default_network_isActive(self.client, self.defult_network)
            if status == "no":
                assert 200 == self.start_default_network(self.defult_network)
            # start VMs
            logging.info("Start create VM in sut1")
            if self.sut_info["os"] == "UBUNTU":
                assert 200 == self.create_vm(vm1_image, host_dev_id_list[0],  self.vm1_name, "ubuntu20.04", "5900")
                assert 200 == self.create_vm(vm2_image, host_dev_id_list[1], self.vm2_name, "ubuntu20.04", "5901")
            else:
>               assert 200 == self.create_vm(vm1_image, host_dev_id_list[0], self.vm1_name, "rhel8.2", "5900")
E               AssertionError: assert 200 == 400
E                +  where 400 = <bound method Test_Network_SRIOV_Stress.create_vm of <Tests.testNics.test_network_sriov_stress.Test_Network_SRIOV_Stress object at 0x7f2d70255470>>('rvm2.img', 'pci_0000_98_01_0', 'VMtest1', 'rhel8.2', '5900')
E                +    where <bound method Test_Network_SRIOV_Stress.create_vm of <Tests.testNics.test_network_sriov_stress.Test_Network_SRIOV_Stress object at 0x7f2d70255470>> = <Tests.testNics.test_network_sriov_stress.Test_Network_SRIOV_Stress object at 0x7f2d70255470>.create_vm
E                +    and   'VMtest1' = <Tests.testNics.test_network_sriov_stress.Test_Network_SRIOV_Stress object at 0x7f2d70255470>.vm1_name

npxtester/Tests/testNics/test_network_sriov_stress.py:1041: AssertionError
---------------------------- Captured stdout setup -----------------------------
2022-04-26 18:22:08 - NicTestFixture.py - [line:27] - root - INFO - case_logpath: /root/testconfig/testlogs/2022-04-26/test_PI_Iperf_TCP_Stress_Guests[ipv4-rvm2.img-rvm1.img]_18_22_08/test_PI_Iperf_TCP_Stress_Guests[ipv4-rvm2.img-rvm1.img].log, case_logdir: /root/testconfig/testlogs/2022-04-26/test_PI_Iperf_TCP_Stress_Guests[ipv4-rvm2.img-rvm1.img]_18_22_08
2022-04-26 18:22:08 - NicTestFixture.py - [line:31] - root - INFO - ============================ Starting to run test_PI_Iperf_TCP_Stress_Guests[ipv4-rvm2.img-rvm1.img] case ============================
2022-04-26 18:22:08 - test_network_sriov_stress.py - [line:32] - root - INFO - SSH SUT and setup configurations in the setup function.
2022-04-26 18:22:08 - test_network_sriov_stress.py - [line:50] - root - INFO - ssh to the sut1
2022-04-26 18:22:08 - transport.py - [line:1819] - paramiko.transport - INFO - Connected (version 2.0, client OpenSSH_8.0)
2022-04-26 18:22:08 - transport.py - [line:1819] - paramiko.transport - INFO - Authentication (password) successful!
2022-04-26 18:22:08 - sshInstance.py - [line:28] - root - INFO - SSH on SUT: 10.239.182.80
2022-04-26 18:22:08 - transport.py - [line:1819] - paramiko.transport - INFO - Connected (version 2.0, client OpenSSH_8.0)
2022-04-26 18:22:09 - transport.py - [line:1819] - paramiko.transport - INFO - Authentication (password) successful!
2022-04-26 18:22:09 - sshInstance.py - [line:28] - root - INFO - SSH on SUT: 10.239.182.88
2022-04-26 18:22:09 - test_network_sriov_stress.py - [line:64] - root - INFO - clean up iperf and taskset process...
2022-04-26 18:22:12 - sshInstance.py - [line:50] - root - INFO - pkill -9 iperf
2022-04-26 18:22:12 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:22:20 - sshInstance.py - [line:50] - root - INFO - pkill -9 taskset
2022-04-26 18:22:20 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:22:28 - sshInstance.py - [line:50] - root - INFO - pkill -9 iperf
2022-04-26 18:22:28 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:22:36 - sshInstance.py - [line:50] - root - INFO - pkill -9 taskset
2022-04-26 18:22:36 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:22:41 - sftp.py - [line:158] - paramiko.transport.sftp - INFO - [chan 3] Opened sftp connection (server version 3)
2022-04-26 18:22:41 - sshInstance.py - [line:199] - root - INFO - start to rmmod irdma....
2022-04-26 18:22:44 - sshInstance.py - [line:50] - root - INFO - rmmod irdma
2022-04-26 18:22:44 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:22:49 - sshInstance.py - [line:202] - root - INFO - finished rmmod irdma....
2022-04-26 18:22:49 - sshInstance.py - [line:203] - root - INFO - start to rmmod ice....
2022-04-26 18:22:52 - sshInstance.py - [line:50] - root - INFO - rmmod ice
2022-04-26 18:23:03 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:23:08 - sshInstance.py - [line:206] - root - INFO - finished rmmod ice....
2022-04-26 18:23:08 - sshInstance.py - [line:208] - root - INFO - start to modprobe ice....
2022-04-26 18:23:11 - sshInstance.py - [line:50] - root - INFO - modprobe ice
2022-04-26 18:23:48 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:23:53 - sshInstance.py - [line:210] - root - INFO - finished modprobe ice....
2022-04-26 18:23:56 - sshInstance.py - [line:50] - root - INFO - ethtool -i ens43f0
2022-04-26 18:23:56 - sshInstance.py - [line:54] - root - INFO - driver: ice
version: 4.18.0-369.el8.x86_64
firmware-version: 3.10 0x8000ad67 1.3106.0
expansion-rom-version: 
bus-info: 0000:98:00.0
supports-statistics: yes
supports-test: yes
supports-eeprom-access: yes
supports-register-dump: yes
supports-priv-flags: yes

2022-04-26 18:24:01 - test_network_sriov_stress.py - [line:72] - root - INFO - try to get ipv6 of pf for redhat...
2022-04-26 18:24:01 - sshInstance.py - [line:187] - root - INFO - starting to delete network of ens43f0:
2022-04-26 18:24:07 - sshInstance.py - [line:99] - root - INFO - Activate the web console with: systemctl enable --now cockpit.socket
Register this system with Red Hat Insights: insights-client --register
Create an account or view all your systems at https://red.ht/insights-dashboard
Last login: Tue Apr 26 18:32:36 2022 from 10.112.97.60
[root@npx-auto-SPR-quanta ~]# nmcli connection delete ens43f0
Connection 'ens43f0' (6c0fc539-da39-434d-ae5c-22933ff59fb7) successfully deleted.
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:24:10 - sshInstance.py - [line:189] - root - INFO - restart networkManager to make setting valid
2022-04-26 18:24:16 - sshInstance.py - [line:99] - root - INFO - systemctl restart NetworkManager
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:24:19 - sshInstance.py - [line:192] - root - INFO - starting to add network of ens43f0:
2022-04-26 18:24:25 - sshInstance.py - [line:99] - root - INFO - nmcli connection add type ethernet con-name ens43f00 ifname ens43f0
Connection 'ens43f0' (75a108ed-a24b-47b9-81d0-185d4f47aa23) successfully added.
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:24:28 - sshInstance.py - [line:195] - root - INFO - restart networkManager to make setting valid
2022-04-26 18:24:34 - sshInstance.py - [line:99] - root - INFO - systemctl restart NetworkManager
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:24:37 - test_network_sriov_stress.py - [line:78] - root - INFO - try to get ipv6 for ens785f0
2022-04-26 18:24:37 - test_network_sriov_stress.py - [line:80] - root - INFO - getting ipv6 in redhat.
2022-04-26 18:24:37 - sshInstance.py - [line:187] - root - INFO - starting to delete network of ens785f0:
2022-04-26 18:24:43 - sshInstance.py - [line:99] - root - INFO - Activate the web console with: systemctl enable --now cockpit.socket
This system is not registered to Red Hat Insights. See https://cloud.redhat.com/
To register this system, run: insights-client --register
Last login: Tue Apr 26 18:33:19 2022 from 10.112.97.60
xhost:  unable to open display ""
[root@CYP10RT ~]# nmcli connection delete ens785f0
Connection 'ens785f0' (17a89cda-b40b-4935-a8c9-5d221e72d4c3) successfully deleted.
[root@CYP10RT ~]# 
2022-04-26 18:24:46 - sshInstance.py - [line:189] - root - INFO - restart networkManager to make setting valid
2022-04-26 18:24:52 - sshInstance.py - [line:99] - root - INFO - systemctl restart NetworkManager
[root@CYP10RT ~]# 
2022-04-26 18:24:55 - sshInstance.py - [line:192] - root - INFO - starting to add network of ens785f0:
2022-04-26 18:25:01 - sshInstance.py - [line:99] - root - INFO - nmcli connection add type ethernet con-name ens785f0 ifname enss785f0
Connection 'ens785f0' (dcd37f98-827d-4263-942c-ea2587552429) successfully added.
[root@CYP10RT ~]# 
2022-04-26 18:25:04 - sshInstance.py - [line:195] - root - INFO - restart networkManager to make setting valid
2022-04-26 18:25:10 - sshInstance.py - [line:99] - root - INFO - systemctl restart NetworkManager
[root@CYP10RT ~]# 
2022-04-26 18:25:13 - test_network_sriov_stress.py - [line:88] - root - INFO - trying to get ipv6 addr for pf1
2022-04-26 18:25:16 - sshInstance.py - [line:50] - root - INFO - ifconfig ens43f0
2022-04-26 18:25:16 - sshInstance.py - [line:54] - root - INFO - ens43f0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
        inet6 fe80::4ec8:ba5b:2f1c:85ba  prefixlen 64  scopeid 0x20<link>
        ether b4:96:91:a0:20:d8  txqueuelen 1000  (Ethernet)
        RX packets 0  bytes 0 (0.0 B)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 23  bytes 4256 (4.1 KiB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0


2022-04-26 18:25:24 - sshInstance.py - [line:50] - root - INFO - ifconfig ens785f0
2022-04-26 18:25:24 - sshInstance.py - [line:54] - root - INFO - ens785f0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
        inet6 fe80::6bad:883c:a61:3f8e  prefixlen 64  scopeid 0x20<link>
        ether b4:96:91:a0:21:70  txqueuelen 1000  (Ethernet)
        RX packets 27872973019  bytes 42172095226188 (38.3 TiB)
        RX errors 0  dropped 9838  overruns 0  frame 0
        TX packets 756505624  bytes 52161214759 (48.5 GiB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0


----------------------------- Captured stdout call -----------------------------
2022-04-26 18:25:32 - sshInstance.py - [line:50] - root - INFO - /opt/APP/utility/DPDK_install/dpdk-22.03/usertools/dpdk-devbind.py -s | grep ens43f0 | awk '{print $1;}'
2022-04-26 18:25:33 - sshInstance.py - [line:54] - root - INFO - 0000:98:00.0

2022-04-26 18:25:38 - test_network_sriov_stress.py - [line:139] - root - INFO - pf_id was found: 0000:98:00.0

2022-04-26 18:25:38 - test_network_sriov_stress.py - [line:979] - root - INFO - format_pf_id is 0000\:98\:00.0

2022-04-26 18:25:38 - test_network_sriov_stress.py - [line:982] - root - INFO - pf_id_key: 98
2022-04-26 18:25:38 - test_network_sriov_stress.py - [line:986] - root - INFO - assign sut1 pf ens43f0 ip
2022-04-26 18:25:44 - sshInstance.py - [line:99] - root - INFO - ifconfig ens43f0 192.168.10.10
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:25:47 - test_network_sriov_stress.py - [line:348] - root - INFO - Successfully assigned ip to ethernet: ens43f0
2022-04-26 18:25:47 - test_network_sriov_stress.py - [line:991] - root - INFO - assign sut2 pf ens785f0 ip
2022-04-26 18:25:53 - sshInstance.py - [line:99] - root - INFO - ifconfig ens785f0 192.168.10.11
[root@CYP10RT ~]# 
2022-04-26 18:25:56 - test_network_sriov_stress.py - [line:348] - root - INFO - Successfully assigned ip to ethernet: ens785f0
2022-04-26 18:25:56 - test_network_sriov_stress.py - [line:145] - root - INFO - virtulize sut1 pf to 4 vfs
2022-04-26 18:25:59 - sshInstance.py - [line:50] - root - INFO - echo 4 > /sys/class/net/ens43f0/device/sriov_numvfs
2022-04-26 18:26:03 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:26:08 - test_network_sriov_stress.py - [line:154] - root - INFO - Successfully Virtualized PF to VFs.
2022-04-26 18:26:11 - sshInstance.py - [line:50] - root - INFO - lspci | grep "Virtual" |grep 98 | awk '{print $1;}'list
2022-04-26 18:26:11 - sshInstance.py - [line:54] - root - INFO - 98:01.0
98:01.1
98:01.2
98:01.3

2022-04-26 18:26:16 - test_network_sriov_stress.py - [line:168] - root - INFO - Succssfully Gotten vf_id list:

2022-04-26 18:26:19 - sshInstance.py - [line:50] - root - INFO - modprobe vfio-pci

2022-04-26 18:26:19 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:26:24 - test_network_sriov_stress.py - [line:188] - root - INFO - start to bind drive in sut1
2022-04-26 18:26:27 - sshInstance.py - [line:50] - root - INFO - /opt/APP/utility/DPDK_install/dpdk-22.03/usertools/dpdk-devbind.py -b vfio-pci 98:01.0
2022-04-26 18:26:30 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:26:35 - test_network_sriov_stress.py - [line:202] - root - INFO - Successfuly bound VF to vfio-pci
2022-04-26 18:26:38 - sshInstance.py - [line:50] - root - INFO - /opt/APP/utility/DPDK_install/dpdk-22.03/usertools/dpdk-devbind.py -b vfio-pci 98:01.1
2022-04-26 18:26:40 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:26:45 - test_network_sriov_stress.py - [line:202] - root - INFO - Successfuly bound VF to vfio-pci
2022-04-26 18:26:45 - test_network_sriov_stress.py - [line:1011] - root - INFO - Start get vf device id in sut1
2022-04-26 18:26:45 - test_network_sriov_stress.py - [line:1013] - root - INFO - lspci -Dnn | grep 98:01.1
2022-04-26 18:26:48 - sshInstance.py - [line:50] - root - INFO - lspci -Dnn | grep 98:01.1
2022-04-26 18:26:48 - sshInstance.py - [line:54] - root - INFO - 0000:98:01.1 Ethernet controller [0200]: Intel Corporation Ethernet Adaptive Virtual Function [8086:1889] (rev 02)

2022-04-26 18:26:53 - test_network_sriov_stress.py - [line:1027] - root - INFO - Successfully get vf device id: 8086:1889
2022-04-26 18:26:53 - test_network_sriov_stress.py - [line:225] - root - INFO - get default network info: virsh net-info default | grep "Active" | awk '{print $2;}'
2022-04-26 18:26:56 - sshInstance.py - [line:50] - root - INFO - virsh net-info default | grep "Active" | awk '{print $2;}'
2022-04-26 18:26:57 - sshInstance.py - [line:54] - root - INFO - yes

2022-04-26 18:27:02 - test_network_sriov_stress.py - [line:228] - root - INFO - Default network is active? yes

2022-04-26 18:27:02 - test_network_sriov_stress.py - [line:1036] - root - INFO - Start create VM in sut1
2022-04-26 18:27:02 - test_network_sriov_stress.py - [line:258] - root - INFO - try to create VM with the cmd1: virt-install --name VMtest1 --ram 4096 --cpu host --vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk path=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=0.0.0.0,port=5900 --noautoconsole

2022-04-26 18:27:06 - sshInstance.py - [line:75] - root - INFO - virt-install --name VMtest1 --ram 4096 --cpu host ---vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk ppath=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=00.0.0.0,port=5900 --noautoconsole
2022-04-26 18:27:08 - sshInstance.py - [line:75] - root - INFO - ERROR    Disk /home/rvm2.img is already in use by other guests ['VMtest2']. (Use --check path_in_use=off or --check all=off to override)
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:27:14 - sshInstance.py - [line:50] - root - INFO - virsh list --all
2022-04-26 18:27:14 - sshInstance.py - [line:54] - root - INFO -  Id   Name      State
--------------------------
 -    VMtest1   shut off
 -    VMtest2   shut off


2022-04-26 18:27:19 - test_network_sriov_stress.py - [line:271] - root - INFO - Failed to create a VM: virt-install --name VMtest1 --ram 4096 --cpu host ---vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk ppath=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=00.0.0.0,port=5900 --noautoconsole
ERROR    Disk /home/rvm2.img is already in use by other guests ['VMtest2']. (Use --check path_in_use=off or --check all=off to override)
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:27:19 - test_network_sriov_stress.py - [line:272] - root - INFO - Failed to create a VM: 
2022-04-26 18:27:19 - test_network_sriov_stress.py - [line:258] - root - INFO - try to create VM with the cmd1: virt-install --name VMtest1 --ram 4096 --cpu host --vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk path=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=0.0.0.0,port=5900 --noautoconsole

2022-04-26 18:27:23 - sshInstance.py - [line:75] - root - INFO - virt-install --name VMtest1 --ram 4096 --cpu host ---vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk ppath=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=00.0.0.0,port=5900 --noautoconsole
2022-04-26 18:27:25 - sshInstance.py - [line:75] - root - INFO - ERROR    Disk /home/rvm2.img is already in use by other guests ['VMtest2']. (Use --check path_in_use=off or --check all=off to override)
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:27:31 - sshInstance.py - [line:50] - root - INFO - virsh list --all
2022-04-26 18:27:31 - sshInstance.py - [line:54] - root - INFO -  Id   Name      State
--------------------------
 -    VMtest1   shut off
 -    VMtest2   shut off


2022-04-26 18:27:36 - test_network_sriov_stress.py - [line:271] - root - INFO - Failed to create a VM: virt-install --name VMtest1 --ram 4096 --cpu host ---vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk ppath=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=00.0.0.0,port=5900 --noautoconsole
ERROR    Disk /home/rvm2.img is already in use by other guests ['VMtest2']. (Use --check path_in_use=off or --check all=off to override)
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:27:36 - test_network_sriov_stress.py - [line:272] - root - INFO - Failed to create a VM: 
2022-04-26 18:27:36 - test_network_sriov_stress.py - [line:258] - root - INFO - try to create VM with the cmd1: virt-install --name VMtest1 --ram 4096 --cpu host --vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk path=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=0.0.0.0,port=5900 --noautoconsole

2022-04-26 18:27:40 - sshInstance.py - [line:75] - root - INFO - virt-install --name VMtest1 --ram 4096 --cpu host ---vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk ppath=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=00.0.0.0,port=5900 --noautoconsole
2022-04-26 18:27:42 - sshInstance.py - [line:75] - root - INFO - ERROR    Disk /home/rvm2.img is already in use by other guests ['VMtest2']. (Use --check path_in_use=off or --check all=off to override)
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:27:48 - sshInstance.py - [line:50] - root - INFO - virsh list --all
2022-04-26 18:27:48 - sshInstance.py - [line:54] - root - INFO -  Id   Name      State
--------------------------
 -    VMtest1   shut off
 -    VMtest2   shut off


2022-04-26 18:27:53 - test_network_sriov_stress.py - [line:271] - root - INFO - Failed to create a VM: virt-install --name VMtest1 --ram 4096 --cpu host ---vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk ppath=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=00.0.0.0,port=5900 --noautoconsole
ERROR    Disk /home/rvm2.img is already in use by other guests ['VMtest2']. (Use --check path_in_use=off or --check all=off to override)
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:27:53 - test_network_sriov_stress.py - [line:272] - root - INFO - Failed to create a VM: 
2022-04-26 18:27:53 - test_network_sriov_stress.py - [line:280] - root - ERROR - Failed to create a VM: VMtest1)
------------------------------ Captured log call -------------------------------
INFO     root:sshInstance.py:50 /opt/APP/utility/DPDK_install/dpdk-22.03/usertools/dpdk-devbind.py -s | grep ens43f0 | awk '{print $1;}'
INFO     root:sshInstance.py:54 0000:98:00.0

INFO     root:test_network_sriov_stress.py:139 pf_id was found: 0000:98:00.0

INFO     root:test_network_sriov_stress.py:979 format_pf_id is 0000\:98\:00.0

INFO     root:test_network_sriov_stress.py:982 pf_id_key: 98
INFO     root:test_network_sriov_stress.py:986 assign sut1 pf ens43f0 ip
INFO     root:sshInstance.py:99 ifconfig ens43f0 192.168.10.10
[root@npx-auto-SPR-quanta ~]# 
INFO     root:test_network_sriov_stress.py:348 Successfully assigned ip to ethernet: ens43f0
INFO     root:test_network_sriov_stress.py:991 assign sut2 pf ens785f0 ip
INFO     root:sshInstance.py:99 ifconfig ens785f0 192.168.10.11
[root@CYP10RT ~]# 
INFO     root:test_network_sriov_stress.py:348 Successfully assigned ip to ethernet: ens785f0
INFO     root:test_network_sriov_stress.py:145 virtulize sut1 pf to 4 vfs
INFO     root:sshInstance.py:50 echo 4 > /sys/class/net/ens43f0/device/sriov_numvfs
INFO     root:sshInstance.py:54 
INFO     root:test_network_sriov_stress.py:154 Successfully Virtualized PF to VFs.
INFO     root:sshInstance.py:50 lspci | grep "Virtual" |grep 98 | awk '{print $1;}'list
INFO     root:sshInstance.py:54 98:01.0
98:01.1
98:01.2
98:01.3

INFO     root:test_network_sriov_stress.py:168 Succssfully Gotten vf_id list:

INFO     root:sshInstance.py:50 modprobe vfio-pci

INFO     root:sshInstance.py:54 
INFO     root:test_network_sriov_stress.py:188 start to bind drive in sut1
INFO     root:sshInstance.py:50 /opt/APP/utility/DPDK_install/dpdk-22.03/usertools/dpdk-devbind.py -b vfio-pci 98:01.0
INFO     root:sshInstance.py:54 
INFO     root:test_network_sriov_stress.py:202 Successfuly bound VF to vfio-pci
INFO     root:sshInstance.py:50 /opt/APP/utility/DPDK_install/dpdk-22.03/usertools/dpdk-devbind.py -b vfio-pci 98:01.1
INFO     root:sshInstance.py:54 
INFO     root:test_network_sriov_stress.py:202 Successfuly bound VF to vfio-pci
INFO     root:test_network_sriov_stress.py:1011 Start get vf device id in sut1
INFO     root:test_network_sriov_stress.py:1013 lspci -Dnn | grep 98:01.1
INFO     root:sshInstance.py:50 lspci -Dnn | grep 98:01.1
INFO     root:sshInstance.py:54 0000:98:01.1 Ethernet controller [0200]: Intel Corporation Ethernet Adaptive Virtual Function [8086:1889] (rev 02)

INFO     root:test_network_sriov_stress.py:1027 Successfully get vf device id: 8086:1889
INFO     root:test_network_sriov_stress.py:225 get default network info: virsh net-info default | grep "Active" | awk '{print $2;}'
INFO     root:sshInstance.py:50 virsh net-info default | grep "Active" | awk '{print $2;}'
INFO     root:sshInstance.py:54 yes

INFO     root:test_network_sriov_stress.py:228 Default network is active? yes

INFO     root:test_network_sriov_stress.py:1036 Start create VM in sut1
INFO     root:test_network_sriov_stress.py:258 try to create VM with the cmd1: virt-install --name VMtest1 --ram 4096 --cpu host --vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk path=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=0.0.0.0,port=5900 --noautoconsole

INFO     root:sshInstance.py:75 virt-install --name VMtest1 --ram 4096 --cpu host ---vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk ppath=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=00.0.0.0,port=5900 --noautoconsole
INFO     root:sshInstance.py:75 ERROR    Disk /home/rvm2.img is already in use by other guests ['VMtest2']. (Use --check path_in_use=off or --check all=off to override)
[root@npx-auto-SPR-quanta ~]# 
INFO     root:sshInstance.py:50 virsh list --all
INFO     root:sshInstance.py:54  Id   Name      State
--------------------------
 -    VMtest1   shut off
 -    VMtest2   shut off


INFO     root:test_network_sriov_stress.py:271 Failed to create a VM: virt-install --name VMtest1 --ram 4096 --cpu host ---vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk ppath=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=00.0.0.0,port=5900 --noautoconsole
ERROR    Disk /home/rvm2.img is already in use by other guests ['VMtest2']. (Use --check path_in_use=off or --check all=off to override)
[root@npx-auto-SPR-quanta ~]# 
INFO     root:test_network_sriov_stress.py:272 Failed to create a VM: 
INFO     root:test_network_sriov_stress.py:258 try to create VM with the cmd1: virt-install --name VMtest1 --ram 4096 --cpu host --vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk path=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=0.0.0.0,port=5900 --noautoconsole

INFO     root:sshInstance.py:75 virt-install --name VMtest1 --ram 4096 --cpu host ---vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk ppath=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=00.0.0.0,port=5900 --noautoconsole
INFO     root:sshInstance.py:75 ERROR    Disk /home/rvm2.img is already in use by other guests ['VMtest2']. (Use --check path_in_use=off or --check all=off to override)
[root@npx-auto-SPR-quanta ~]# 
INFO     root:sshInstance.py:50 virsh list --all
INFO     root:sshInstance.py:54  Id   Name      State
--------------------------
 -    VMtest1   shut off
 -    VMtest2   shut off


INFO     root:test_network_sriov_stress.py:271 Failed to create a VM: virt-install --name VMtest1 --ram 4096 --cpu host ---vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk ppath=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=00.0.0.0,port=5900 --noautoconsole
ERROR    Disk /home/rvm2.img is already in use by other guests ['VMtest2']. (Use --check path_in_use=off or --check all=off to override)
[root@npx-auto-SPR-quanta ~]# 
INFO     root:test_network_sriov_stress.py:272 Failed to create a VM: 
INFO     root:test_network_sriov_stress.py:258 try to create VM with the cmd1: virt-install --name VMtest1 --ram 4096 --cpu host --vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk path=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=0.0.0.0,port=5900 --noautoconsole

INFO     root:sshInstance.py:75 virt-install --name VMtest1 --ram 4096 --cpu host ---vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk ppath=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=00.0.0.0,port=5900 --noautoconsole
INFO     root:sshInstance.py:75 ERROR    Disk /home/rvm2.img is already in use by other guests ['VMtest2']. (Use --check path_in_use=off or --check all=off to override)
[root@npx-auto-SPR-quanta ~]# 
INFO     root:sshInstance.py:50 virsh list --all
INFO     root:sshInstance.py:54  Id   Name      State
--------------------------
 -    VMtest1   shut off
 -    VMtest2   shut off


INFO     root:test_network_sriov_stress.py:271 Failed to create a VM: virt-install --name VMtest1 --ram 4096 --cpu host ---vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk ppath=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=00.0.0.0,port=5900 --noautoconsole
ERROR    Disk /home/rvm2.img is already in use by other guests ['VMtest2']. (Use --check path_in_use=off or --check all=off to override)
[root@npx-auto-SPR-quanta ~]# 
INFO     root:test_network_sriov_stress.py:272 Failed to create a VM: 
ERROR    root:test_network_sriov_stress.py:280 Failed to create a VM: VMtest1)
_ Test_Network_SRIOV_Stress.test_PI_Iperf_TCP_Stress_Guests[ipv6-rvm2.img-rvm1.img] _

self = <Tests.testNics.test_network_sriov_stress.Test_Network_SRIOV_Stress object at 0x7f2d700a4e10>
vm1_image = 'rvm2.img', vm2_image = 'rvm1.img', ip_type = 'ipv6'

    @pytest.mark.usefixtures("fbefore")
    @pytest.mark.nicAll
    @pytest.mark.nicStress
    @pytest.mark.nicIperfTcpGuestStress
    @pytest.mark.SriovVfIperf
    @pytest.mark.parametrize('vm1_image, vm2_image,', vm_image)
    @pytest.mark.parametrize('ip_type', run_type)
    def test_PI_Iperf_TCP_Stress_Guests(self, vm1_image, vm2_image, ip_type):
        iperf_log_name = "iperf_vm1_vm2_2hours.txt"
        # run_type = settings.__getattribute__("run_type")
        pf_id, status = self.get_pf_id(self.client, self.pf_name)
        # transfer pf_id to 0000\:00\:00.0 format
        if not pf_id:
            assert 200 == status
        else:
            pf_id_format = pf_id.replace(":", "\\:", 2)
            logging.info("format_pf_id is {}".format(pf_id_format))
            # get the number key of pf_id
            pf_id_key = pf_id.split(":")[1]
            logging.info("pf_id_key: {}".format(pf_id_key))
            # assign IP to PF in SUT and sut2
            sut1_pf_ip = "192.168.10.10"
            sut2_pf_ip = "192.168.10.11"
            logging.info("assign sut1 pf {} ip".format(self.pf_name))
            st = self.assign_ip_ehternet(self.session, sut1_pf_ip, self.pf_name)
            if st != 200:
                logging.error("Fail to assign sut1 pf {} failed".format(self.pf_name))
                assert 200 == 400, "Fail to assign sut1 pf {} failed"
            logging.info("assign sut2 pf {} ip".format(self.pf2_name))
            st = self.assign_ip_ehternet(self.session2, sut2_pf_ip, self.pf2_name)
            if st !=200:
                logging.error("Fail to assign sut2 pf {} ".format(self.pf2_name))
                assert 200 == 400, "Fail to assign sut1 pf {}"
    
            # virtulize the pf to vfs
            assert 200 == self.virtualize_pf_to_vfs(self.pf_name)
            # get vf ids
            vf_id_list, status = self.get_vf_ids(self.client, pf_id_key)
            vf_id_list = [i.strip() for i in vf_id_list]
            if status == 200:
                # modprobe vfio-pci
                assert 200 == self.modprobe("vfio-pci")
                # bind vf with vfio-pci
                host_dev_id_list, status = self.bind_vf_to_vfio_pci(self.client, vf_id_list)
                assert 200 == status
            else:
                assert 200 == status
            # get vF device id
            logging.info("Start get vf device id in sut1")
            cmd = "lspci -Dnn | grep %s" % (vf_id_list[1])
            logging.info(cmd)
            vf_device_id = ""
            vf_device_id_rs, error = self.ssh_sut.ssh_exec_cmd(self.client, cmd)
            vf_device_id_rs = vf_device_id_rs.strip()
            if vf_device_id_rs:
                st = False
                vf_device_id = None
                for one in vf_device_id_rs.split(" "):
                    one = " " + one + " "
                    if one.find(" [") > -1 and one.find("] ") > -1 and one.find(":") > -1:
                        vf_device_id = one.replace("[", "").replace("]", "").strip()
                if not vf_device_id:
                    logging.error("Fail to get vf_device_id")
                    assert 200 == 400, "vf_device_id is not found"
                logging.info("Successfully get vf device id: {}".format(vf_device_id))
            else:
                logging.error("Fail to get vf device id.")
                assert 200 == 400
            # set network
            status = self.default_network_isActive(self.client, self.defult_network)
            if status == "no":
                assert 200 == self.start_default_network(self.defult_network)
            # start VMs
            logging.info("Start create VM in sut1")
            if self.sut_info["os"] == "UBUNTU":
                assert 200 == self.create_vm(vm1_image, host_dev_id_list[0],  self.vm1_name, "ubuntu20.04", "5900")
                assert 200 == self.create_vm(vm2_image, host_dev_id_list[1], self.vm2_name, "ubuntu20.04", "5901")
            else:
>               assert 200 == self.create_vm(vm1_image, host_dev_id_list[0], self.vm1_name, "rhel8.2", "5900")
E               AssertionError: assert 200 == 400
E                +  where 400 = <bound method Test_Network_SRIOV_Stress.create_vm of <Tests.testNics.test_network_sriov_stress.Test_Network_SRIOV_Stress object at 0x7f2d700a4e10>>('rvm2.img', 'pci_0000_98_01_0', 'VMtest1', 'rhel8.2', '5900')
E                +    where <bound method Test_Network_SRIOV_Stress.create_vm of <Tests.testNics.test_network_sriov_stress.Test_Network_SRIOV_Stress object at 0x7f2d700a4e10>> = <Tests.testNics.test_network_sriov_stress.Test_Network_SRIOV_Stress object at 0x7f2d700a4e10>.create_vm
E                +    and   'VMtest1' = <Tests.testNics.test_network_sriov_stress.Test_Network_SRIOV_Stress object at 0x7f2d700a4e10>.vm1_name

npxtester/Tests/testNics/test_network_sriov_stress.py:1041: AssertionError
---------------------------- Captured stdout setup -----------------------------
2022-04-26 18:29:03 - NicTestFixture.py - [line:27] - root - INFO - case_logpath: /root/testconfig/testlogs/2022-04-26/test_PI_Iperf_TCP_Stress_Guests[ipv6-rvm2.img-rvm1.img]_18_29_03/test_PI_Iperf_TCP_Stress_Guests[ipv6-rvm2.img-rvm1.img].log, case_logdir: /root/testconfig/testlogs/2022-04-26/test_PI_Iperf_TCP_Stress_Guests[ipv6-rvm2.img-rvm1.img]_18_29_03
2022-04-26 18:29:03 - NicTestFixture.py - [line:31] - root - INFO - ============================ Starting to run test_PI_Iperf_TCP_Stress_Guests[ipv6-rvm2.img-rvm1.img] case ============================
2022-04-26 18:29:03 - test_network_sriov_stress.py - [line:32] - root - INFO - SSH SUT and setup configurations in the setup function.
2022-04-26 18:29:03 - test_network_sriov_stress.py - [line:50] - root - INFO - ssh to the sut1
2022-04-26 18:29:03 - transport.py - [line:1819] - paramiko.transport - INFO - Connected (version 2.0, client OpenSSH_8.0)
2022-04-26 18:29:03 - transport.py - [line:1819] - paramiko.transport - INFO - Authentication (password) successful!
2022-04-26 18:29:03 - sshInstance.py - [line:28] - root - INFO - SSH on SUT: 10.239.182.80
2022-04-26 18:29:03 - transport.py - [line:1819] - paramiko.transport - INFO - Connected (version 2.0, client OpenSSH_8.0)
2022-04-26 18:29:04 - transport.py - [line:1819] - paramiko.transport - INFO - Authentication (password) successful!
2022-04-26 18:29:04 - sshInstance.py - [line:28] - root - INFO - SSH on SUT: 10.239.182.88
2022-04-26 18:29:04 - test_network_sriov_stress.py - [line:64] - root - INFO - clean up iperf and taskset process...
2022-04-26 18:29:07 - sshInstance.py - [line:50] - root - INFO - pkill -9 iperf
2022-04-26 18:29:07 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:29:15 - sshInstance.py - [line:50] - root - INFO - pkill -9 taskset
2022-04-26 18:29:15 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:29:23 - sshInstance.py - [line:50] - root - INFO - pkill -9 iperf
2022-04-26 18:29:23 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:29:31 - sshInstance.py - [line:50] - root - INFO - pkill -9 taskset
2022-04-26 18:29:31 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:29:36 - sftp.py - [line:158] - paramiko.transport.sftp - INFO - [chan 3] Opened sftp connection (server version 3)
2022-04-26 18:29:36 - sshInstance.py - [line:199] - root - INFO - start to rmmod irdma....
2022-04-26 18:29:39 - sshInstance.py - [line:50] - root - INFO - rmmod irdma
2022-04-26 18:29:39 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:29:44 - sshInstance.py - [line:202] - root - INFO - finished rmmod irdma....
2022-04-26 18:29:44 - sshInstance.py - [line:203] - root - INFO - start to rmmod ice....
2022-04-26 18:29:47 - sshInstance.py - [line:50] - root - INFO - rmmod ice
2022-04-26 18:29:58 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:30:03 - sshInstance.py - [line:206] - root - INFO - finished rmmod ice....
2022-04-26 18:30:03 - sshInstance.py - [line:208] - root - INFO - start to modprobe ice....
2022-04-26 18:30:06 - sshInstance.py - [line:50] - root - INFO - modprobe ice
2022-04-26 18:30:43 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:30:48 - sshInstance.py - [line:210] - root - INFO - finished modprobe ice....
2022-04-26 18:30:51 - sshInstance.py - [line:50] - root - INFO - ethtool -i ens43f0
2022-04-26 18:30:51 - sshInstance.py - [line:54] - root - INFO - driver: ice
version: 4.18.0-369.el8.x86_64
firmware-version: 3.10 0x8000ad67 1.3106.0
expansion-rom-version: 
bus-info: 0000:98:00.0
supports-statistics: yes
supports-test: yes
supports-eeprom-access: yes
supports-register-dump: yes
supports-priv-flags: yes

2022-04-26 18:30:56 - test_network_sriov_stress.py - [line:72] - root - INFO - try to get ipv6 of pf for redhat...
2022-04-26 18:30:56 - sshInstance.py - [line:187] - root - INFO - starting to delete network of ens43f0:
2022-04-26 18:31:02 - sshInstance.py - [line:99] - root - INFO - Activate the web console with: systemctl enable --now cockpit.socket
Register this system with Red Hat Insights: insights-client --register
Create an account or view all your systems at https://red.ht/insights-dashboard
Last login: Tue Apr 26 18:39:40 2022 from 10.112.97.60
[root@npx-auto-SPR-quanta ~]# nmcli connection delete ens43f0
Connection 'ens43f0' (75a108ed-a24b-47b9-81d0-185d4f47aa23) successfully deleted.
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:31:05 - sshInstance.py - [line:189] - root - INFO - restart networkManager to make setting valid
2022-04-26 18:31:11 - sshInstance.py - [line:99] - root - INFO - systemctl restart NetworkManager
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:31:14 - sshInstance.py - [line:192] - root - INFO - starting to add network of ens43f0:
2022-04-26 18:31:20 - sshInstance.py - [line:99] - root - INFO - nmcli connection add type ethernet con-name ens43f00 ifname ens43f0
Connection 'ens43f0' (dd4fc487-f122-4c64-8488-54069f402b18) successfully added.
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:31:23 - sshInstance.py - [line:195] - root - INFO - restart networkManager to make setting valid
2022-04-26 18:31:29 - sshInstance.py - [line:99] - root - INFO - systemctl restart NetworkManager
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:31:32 - test_network_sriov_stress.py - [line:78] - root - INFO - try to get ipv6 for ens785f0
2022-04-26 18:31:32 - test_network_sriov_stress.py - [line:80] - root - INFO - getting ipv6 in redhat.
2022-04-26 18:31:32 - sshInstance.py - [line:187] - root - INFO - starting to delete network of ens785f0:
2022-04-26 18:31:38 - sshInstance.py - [line:99] - root - INFO - Activate the web console with: systemctl enable --now cockpit.socket
This system is not registered to Red Hat Insights. See https://cloud.redhat.com/
To register this system, run: insights-client --register
Last login: Tue Apr 26 18:39:50 2022 from 10.112.97.60
xhost:  unable to open display ""
[root@CYP10RT ~]# nmcli connection delete ens785f0
Connection 'ens785f0' (dcd37f98-827d-4263-942c-ea2587552429) successfully deleted.
[root@CYP10RT ~]# 
2022-04-26 18:31:41 - sshInstance.py - [line:189] - root - INFO - restart networkManager to make setting valid
2022-04-26 18:31:47 - sshInstance.py - [line:99] - root - INFO - systemctl restart NetworkManager
[root@CYP10RT ~]# 
2022-04-26 18:31:50 - sshInstance.py - [line:192] - root - INFO - starting to add network of ens785f0:
2022-04-26 18:31:56 - sshInstance.py - [line:99] - root - INFO - nmcli connection add type ethernet con-name ens785f0 ifname enss785f0
Connection 'ens785f0' (d75d3875-920d-4e35-9eef-d354e1b6d096) successfully added.
[root@CYP10RT ~]# 
2022-04-26 18:31:59 - sshInstance.py - [line:195] - root - INFO - restart networkManager to make setting valid
2022-04-26 18:32:05 - sshInstance.py - [line:99] - root - INFO - systemctl restart NetworkManager
[root@CYP10RT ~]# 
2022-04-26 18:32:08 - test_network_sriov_stress.py - [line:88] - root - INFO - trying to get ipv6 addr for pf1
2022-04-26 18:32:11 - sshInstance.py - [line:50] - root - INFO - ifconfig ens43f0
2022-04-26 18:32:11 - sshInstance.py - [line:54] - root - INFO - ens43f0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
        inet6 fe80::7b6c:ccd1:eb3a:b437  prefixlen 64  scopeid 0x20<link>
        ether b4:96:91:a0:20:d8  txqueuelen 1000  (Ethernet)
        RX packets 0  bytes 0 (0.0 B)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 40  bytes 7040 (6.8 KiB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0


2022-04-26 18:32:19 - sshInstance.py - [line:50] - root - INFO - ifconfig ens785f0
2022-04-26 18:32:19 - sshInstance.py - [line:54] - root - INFO - ens785f0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
        inet6 fe80::62bb:eabe:e877:807b  prefixlen 64  scopeid 0x20<link>
        ether b4:96:91:a0:21:70  txqueuelen 1000  (Ethernet)
        RX packets 27872973019  bytes 42172095226188 (38.3 TiB)
        RX errors 0  dropped 9838  overruns 0  frame 0
        TX packets 756505678  bytes 52161225973 (48.5 GiB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0


----------------------------- Captured stdout call -----------------------------
2022-04-26 18:32:27 - sshInstance.py - [line:50] - root - INFO - /opt/APP/utility/DPDK_install/dpdk-22.03/usertools/dpdk-devbind.py -s | grep ens43f0 | awk '{print $1;}'
2022-04-26 18:32:28 - sshInstance.py - [line:54] - root - INFO - 0000:98:00.0

2022-04-26 18:32:33 - test_network_sriov_stress.py - [line:139] - root - INFO - pf_id was found: 0000:98:00.0

2022-04-26 18:32:33 - test_network_sriov_stress.py - [line:979] - root - INFO - format_pf_id is 0000\:98\:00.0

2022-04-26 18:32:33 - test_network_sriov_stress.py - [line:982] - root - INFO - pf_id_key: 98
2022-04-26 18:32:33 - test_network_sriov_stress.py - [line:986] - root - INFO - assign sut1 pf ens43f0 ip
2022-04-26 18:32:39 - sshInstance.py - [line:99] - root - INFO - ifconfig ens43f0 192.168.10.10
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:32:42 - test_network_sriov_stress.py - [line:348] - root - INFO - Successfully assigned ip to ethernet: ens43f0
2022-04-26 18:32:42 - test_network_sriov_stress.py - [line:991] - root - INFO - assign sut2 pf ens785f0 ip
2022-04-26 18:32:48 - sshInstance.py - [line:99] - root - INFO - ifconfig ens785f0 192.168.10.11
[root@CYP10RT ~]# 
2022-04-26 18:32:51 - test_network_sriov_stress.py - [line:348] - root - INFO - Successfully assigned ip to ethernet: ens785f0
2022-04-26 18:32:51 - test_network_sriov_stress.py - [line:145] - root - INFO - virtulize sut1 pf to 4 vfs
2022-04-26 18:32:54 - sshInstance.py - [line:50] - root - INFO - echo 4 > /sys/class/net/ens43f0/device/sriov_numvfs
2022-04-26 18:32:59 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:33:04 - test_network_sriov_stress.py - [line:154] - root - INFO - Successfully Virtualized PF to VFs.
2022-04-26 18:33:07 - sshInstance.py - [line:50] - root - INFO - lspci | grep "Virtual" |grep 98 | awk '{print $1;}'list
2022-04-26 18:33:07 - sshInstance.py - [line:54] - root - INFO - 98:01.0
98:01.1
98:01.2
98:01.3

2022-04-26 18:33:12 - test_network_sriov_stress.py - [line:168] - root - INFO - Succssfully Gotten vf_id list:

2022-04-26 18:33:15 - sshInstance.py - [line:50] - root - INFO - modprobe vfio-pci

2022-04-26 18:33:15 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:33:20 - test_network_sriov_stress.py - [line:188] - root - INFO - start to bind drive in sut1
2022-04-26 18:33:23 - sshInstance.py - [line:50] - root - INFO - /opt/APP/utility/DPDK_install/dpdk-22.03/usertools/dpdk-devbind.py -b vfio-pci 98:01.0
2022-04-26 18:33:25 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:33:30 - test_network_sriov_stress.py - [line:202] - root - INFO - Successfuly bound VF to vfio-pci
2022-04-26 18:33:33 - sshInstance.py - [line:50] - root - INFO - /opt/APP/utility/DPDK_install/dpdk-22.03/usertools/dpdk-devbind.py -b vfio-pci 98:01.1
2022-04-26 18:33:36 - sshInstance.py - [line:54] - root - INFO - 
2022-04-26 18:33:41 - test_network_sriov_stress.py - [line:202] - root - INFO - Successfuly bound VF to vfio-pci
2022-04-26 18:33:41 - test_network_sriov_stress.py - [line:1011] - root - INFO - Start get vf device id in sut1
2022-04-26 18:33:41 - test_network_sriov_stress.py - [line:1013] - root - INFO - lspci -Dnn | grep 98:01.1
2022-04-26 18:33:44 - sshInstance.py - [line:50] - root - INFO - lspci -Dnn | grep 98:01.1
2022-04-26 18:33:44 - sshInstance.py - [line:54] - root - INFO - 0000:98:01.1 Ethernet controller [0200]: Intel Corporation Ethernet Adaptive Virtual Function [8086:1889] (rev 02)

2022-04-26 18:33:49 - test_network_sriov_stress.py - [line:1027] - root - INFO - Successfully get vf device id: 8086:1889
2022-04-26 18:33:49 - test_network_sriov_stress.py - [line:225] - root - INFO - get default network info: virsh net-info default | grep "Active" | awk '{print $2;}'
2022-04-26 18:33:52 - sshInstance.py - [line:50] - root - INFO - virsh net-info default | grep "Active" | awk '{print $2;}'
2022-04-26 18:33:53 - sshInstance.py - [line:54] - root - INFO - yes

2022-04-26 18:33:58 - test_network_sriov_stress.py - [line:228] - root - INFO - Default network is active? yes

2022-04-26 18:33:58 - test_network_sriov_stress.py - [line:1036] - root - INFO - Start create VM in sut1
2022-04-26 18:33:58 - test_network_sriov_stress.py - [line:258] - root - INFO - try to create VM with the cmd1: virt-install --name VMtest1 --ram 4096 --cpu host --vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk path=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=0.0.0.0,port=5900 --noautoconsole

2022-04-26 18:34:02 - sshInstance.py - [line:75] - root - INFO - virt-install --name VMtest1 --ram 4096 --cpu host ---vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk ppath=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=00.0.0.0,port=5900 --noautoconsole
2022-04-26 18:34:04 - sshInstance.py - [line:75] - root - INFO - ERROR    Disk /home/rvm2.img is already in use by other guests ['VMtest2']. (Use --check path_in_use=off or --check all=off to override)
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:34:10 - sshInstance.py - [line:50] - root - INFO - virsh list --all
2022-04-26 18:34:10 - sshInstance.py - [line:54] - root - INFO -  Id   Name      State
--------------------------
 -    VMtest1   shut off
 -    VMtest2   shut off


2022-04-26 18:34:15 - test_network_sriov_stress.py - [line:271] - root - INFO - Failed to create a VM: virt-install --name VMtest1 --ram 4096 --cpu host ---vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk ppath=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=00.0.0.0,port=5900 --noautoconsole
ERROR    Disk /home/rvm2.img is already in use by other guests ['VMtest2']. (Use --check path_in_use=off or --check all=off to override)
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:34:15 - test_network_sriov_stress.py - [line:272] - root - INFO - Failed to create a VM: 
2022-04-26 18:34:15 - test_network_sriov_stress.py - [line:258] - root - INFO - try to create VM with the cmd1: virt-install --name VMtest1 --ram 4096 --cpu host --vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk path=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=0.0.0.0,port=5900 --noautoconsole

2022-04-26 18:34:19 - sshInstance.py - [line:75] - root - INFO - virt-install --name VMtest1 --ram 4096 --cpu host ---vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk ppath=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=00.0.0.0,port=5900 --noautoconsole
2022-04-26 18:34:21 - sshInstance.py - [line:75] - root - INFO - ERROR    Disk /home/rvm2.img is already in use by other guests ['VMtest2']. (Use --check path_in_use=off or --check all=off to override)
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:34:27 - sshInstance.py - [line:50] - root - INFO - virsh list --all
2022-04-26 18:34:27 - sshInstance.py - [line:54] - root - INFO -  Id   Name      State
--------------------------
 -    VMtest1   shut off
 -    VMtest2   shut off


2022-04-26 18:34:32 - test_network_sriov_stress.py - [line:271] - root - INFO - Failed to create a VM: virt-install --name VMtest1 --ram 4096 --cpu host ---vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk ppath=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=00.0.0.0,port=5900 --noautoconsole
ERROR    Disk /home/rvm2.img is already in use by other guests ['VMtest2']. (Use --check path_in_use=off or --check all=off to override)
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:34:32 - test_network_sriov_stress.py - [line:272] - root - INFO - Failed to create a VM: 
2022-04-26 18:34:32 - test_network_sriov_stress.py - [line:258] - root - INFO - try to create VM with the cmd1: virt-install --name VMtest1 --ram 4096 --cpu host --vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk path=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=0.0.0.0,port=5900 --noautoconsole

2022-04-26 18:34:36 - sshInstance.py - [line:75] - root - INFO - virt-install --name VMtest1 --ram 4096 --cpu host ---vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk ppath=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=00.0.0.0,port=5900 --noautoconsole
2022-04-26 18:34:38 - sshInstance.py - [line:75] - root - INFO - ERROR    Disk /home/rvm2.img is already in use by other guests ['VMtest2']. (Use --check path_in_use=off or --check all=off to override)
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:34:44 - sshInstance.py - [line:50] - root - INFO - virsh list --all
2022-04-26 18:34:44 - sshInstance.py - [line:54] - root - INFO -  Id   Name      State
--------------------------
 -    VMtest1   shut off
 -    VMtest2   shut off


2022-04-26 18:34:49 - test_network_sriov_stress.py - [line:271] - root - INFO - Failed to create a VM: virt-install --name VMtest1 --ram 4096 --cpu host ---vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk ppath=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=00.0.0.0,port=5900 --noautoconsole
ERROR    Disk /home/rvm2.img is already in use by other guests ['VMtest2']. (Use --check path_in_use=off or --check all=off to override)
[root@npx-auto-SPR-quanta ~]# 
2022-04-26 18:34:49 - test_network_sriov_stress.py - [line:272] - root - INFO - Failed to create a VM: 
2022-04-26 18:34:49 - test_network_sriov_stress.py - [line:280] - root - ERROR - Failed to create a VM: VMtest1)
------------------------------ Captured log call -------------------------------
INFO     root:sshInstance.py:50 /opt/APP/utility/DPDK_install/dpdk-22.03/usertools/dpdk-devbind.py -s | grep ens43f0 | awk '{print $1;}'
INFO     root:sshInstance.py:54 0000:98:00.0

INFO     root:test_network_sriov_stress.py:139 pf_id was found: 0000:98:00.0

INFO     root:test_network_sriov_stress.py:979 format_pf_id is 0000\:98\:00.0

INFO     root:test_network_sriov_stress.py:982 pf_id_key: 98
INFO     root:test_network_sriov_stress.py:986 assign sut1 pf ens43f0 ip
INFO     root:sshInstance.py:99 ifconfig ens43f0 192.168.10.10
[root@npx-auto-SPR-quanta ~]# 
INFO     root:test_network_sriov_stress.py:348 Successfully assigned ip to ethernet: ens43f0
INFO     root:test_network_sriov_stress.py:991 assign sut2 pf ens785f0 ip
INFO     root:sshInstance.py:99 ifconfig ens785f0 192.168.10.11
[root@CYP10RT ~]# 
INFO     root:test_network_sriov_stress.py:348 Successfully assigned ip to ethernet: ens785f0
INFO     root:test_network_sriov_stress.py:145 virtulize sut1 pf to 4 vfs
INFO     root:sshInstance.py:50 echo 4 > /sys/class/net/ens43f0/device/sriov_numvfs
INFO     root:sshInstance.py:54 
INFO     root:test_network_sriov_stress.py:154 Successfully Virtualized PF to VFs.
INFO     root:sshInstance.py:50 lspci | grep "Virtual" |grep 98 | awk '{print $1;}'list
INFO     root:sshInstance.py:54 98:01.0
98:01.1
98:01.2
98:01.3

INFO     root:test_network_sriov_stress.py:168 Succssfully Gotten vf_id list:

INFO     root:sshInstance.py:50 modprobe vfio-pci

INFO     root:sshInstance.py:54 
INFO     root:test_network_sriov_stress.py:188 start to bind drive in sut1
INFO     root:sshInstance.py:50 /opt/APP/utility/DPDK_install/dpdk-22.03/usertools/dpdk-devbind.py -b vfio-pci 98:01.0
INFO     root:sshInstance.py:54 
INFO     root:test_network_sriov_stress.py:202 Successfuly bound VF to vfio-pci
INFO     root:sshInstance.py:50 /opt/APP/utility/DPDK_install/dpdk-22.03/usertools/dpdk-devbind.py -b vfio-pci 98:01.1
INFO     root:sshInstance.py:54 
INFO     root:test_network_sriov_stress.py:202 Successfuly bound VF to vfio-pci
INFO     root:test_network_sriov_stress.py:1011 Start get vf device id in sut1
INFO     root:test_network_sriov_stress.py:1013 lspci -Dnn | grep 98:01.1
INFO     root:sshInstance.py:50 lspci -Dnn | grep 98:01.1
INFO     root:sshInstance.py:54 0000:98:01.1 Ethernet controller [0200]: Intel Corporation Ethernet Adaptive Virtual Function [8086:1889] (rev 02)

INFO     root:test_network_sriov_stress.py:1027 Successfully get vf device id: 8086:1889
INFO     root:test_network_sriov_stress.py:225 get default network info: virsh net-info default | grep "Active" | awk '{print $2;}'
INFO     root:sshInstance.py:50 virsh net-info default | grep "Active" | awk '{print $2;}'
INFO     root:sshInstance.py:54 yes

INFO     root:test_network_sriov_stress.py:228 Default network is active? yes

INFO     root:test_network_sriov_stress.py:1036 Start create VM in sut1
INFO     root:test_network_sriov_stress.py:258 try to create VM with the cmd1: virt-install --name VMtest1 --ram 4096 --cpu host --vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk path=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=0.0.0.0,port=5900 --noautoconsole

INFO     root:sshInstance.py:75 virt-install --name VMtest1 --ram 4096 --cpu host ---vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk ppath=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=00.0.0.0,port=5900 --noautoconsole
INFO     root:sshInstance.py:75 ERROR    Disk /home/rvm2.img is already in use by other guests ['VMtest2']. (Use --check path_in_use=off or --check all=off to override)
[root@npx-auto-SPR-quanta ~]# 
INFO     root:sshInstance.py:50 virsh list --all
INFO     root:sshInstance.py:54  Id   Name      State
--------------------------
 -    VMtest1   shut off
 -    VMtest2   shut off


INFO     root:test_network_sriov_stress.py:271 Failed to create a VM: virt-install --name VMtest1 --ram 4096 --cpu host ---vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk ppath=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=00.0.0.0,port=5900 --noautoconsole
ERROR    Disk /home/rvm2.img is already in use by other guests ['VMtest2']. (Use --check path_in_use=off or --check all=off to override)
[root@npx-auto-SPR-quanta ~]# 
INFO     root:test_network_sriov_stress.py:272 Failed to create a VM: 
INFO     root:test_network_sriov_stress.py:258 try to create VM with the cmd1: virt-install --name VMtest1 --ram 4096 --cpu host --vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk path=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=0.0.0.0,port=5900 --noautoconsole

INFO     root:sshInstance.py:75 virt-install --name VMtest1 --ram 4096 --cpu host ---vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk ppath=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=00.0.0.0,port=5900 --noautoconsole
INFO     root:sshInstance.py:75 ERROR    Disk /home/rvm2.img is already in use by other guests ['VMtest2']. (Use --check path_in_use=off or --check all=off to override)
[root@npx-auto-SPR-quanta ~]# 
INFO     root:sshInstance.py:50 virsh list --all
INFO     root:sshInstance.py:54  Id   Name      State
--------------------------
 -    VMtest1   shut off
 -    VMtest2   shut off


INFO     root:test_network_sriov_stress.py:271 Failed to create a VM: virt-install --name VMtest1 --ram 4096 --cpu host ---vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk ppath=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=00.0.0.0,port=5900 --noautoconsole
ERROR    Disk /home/rvm2.img is already in use by other guests ['VMtest2']. (Use --check path_in_use=off or --check all=off to override)
[root@npx-auto-SPR-quanta ~]# 
INFO     root:test_network_sriov_stress.py:272 Failed to create a VM: 
INFO     root:test_network_sriov_stress.py:258 try to create VM with the cmd1: virt-install --name VMtest1 --ram 4096 --cpu host --vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk path=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=0.0.0.0,port=5900 --noautoconsole

INFO     root:sshInstance.py:75 virt-install --name VMtest1 --ram 4096 --cpu host ---vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk ppath=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=00.0.0.0,port=5900 --noautoconsole
INFO     root:sshInstance.py:75 ERROR    Disk /home/rvm2.img is already in use by other guests ['VMtest2']. (Use --check path_in_use=off or --check all=off to override)
[root@npx-auto-SPR-quanta ~]# 
INFO     root:sshInstance.py:50 virsh list --all
INFO     root:sshInstance.py:54  Id   Name      State
--------------------------
 -    VMtest1   shut off
 -    VMtest2   shut off


INFO     root:test_network_sriov_stress.py:271 Failed to create a VM: virt-install --name VMtest1 --ram 4096 --cpu host ---vcpus=5 --network network=default --hostdev pci_0000_98_01_0 --boot hd --disk ppath=/home/rvm2.img,size=50,format=qcow2 --osinfo rhel8.2 --graphics vnc,listen=00.0.0.0,port=5900 --noautoconsole
ERROR    Disk /home/rvm2.img is already in use by other guests ['VMtest2']. (Use --check path_in_use=off or --check all=off to override)
[root@npx-auto-SPR-quanta ~]# 
INFO     root:test_network_sriov_stress.py:272 Failed to create a VM: 
ERROR    root:test_network_sriov_stress.py:280 Failed to create a VM: VMtest1)
=============================== warnings summary ===============================
npxtester/Tests/testNics/test_iperf_client_4hour.py:90
  /root/.jenkins/workspace/spr-test-nicIperfTcpGuestsStress/npxtester/Tests/testNics/test_iperf_client_4hour.py:90: PytestUnknownMarkWarning: Unknown pytest.mark.iperf_tcp - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/mark.html
    @pytest.mark.iperf_tcp

npxtester/Tests/testNics/test_iperf_client_4hour.py:143
  /root/.jenkins/workspace/spr-test-nicIperfTcpGuestsStress/npxtester/Tests/testNics/test_iperf_client_4hour.py:143: PytestUnknownMarkWarning: Unknown pytest.mark.iperf_udp - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/mark.html
    @pytest.mark.iperf_udp

npxtester/Tests/testNics/test_mtu.py:69
  /root/.jenkins/workspace/spr-test-nicIperfTcpGuestsStress/npxtester/Tests/testNics/test_mtu.py:69: PytestUnknownMarkWarning: Unknown pytest.mark.nicSimple - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/mark.html
    @pytest.mark.nicSimple

npxtester/Tests/testNics/test_mtu.py:108
  /root/.jenkins/workspace/spr-test-nicIperfTcpGuestsStress/npxtester/Tests/testNics/test_mtu.py:108: PytestUnknownMarkWarning: Unknown pytest.mark.nicSimple - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/mark.html
    @pytest.mark.nicSimple

npxtester/Tests/testNics/test_network_sriov_stress.py:600
  /root/.jenkins/workspace/spr-test-nicIperfTcpGuestsStress/npxtester/Tests/testNics/test_network_sriov_stress.py:600: PytestUnknownMarkWarning: Unknown pytest.mark.nicSriov5times - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/mark.html
    @pytest.mark.nicSriov5times

npxtester/Tests/testNics/test_network_sriov_stress.py:727
  /root/.jenkins/workspace/spr-test-nicIperfTcpGuestsStress/npxtester/Tests/testNics/test_network_sriov_stress.py:727: PytestUnknownMarkWarning: Unknown pytest.mark.nicSriov2hours - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/mark.html
    @pytest.mark.nicSriov2hours

npxtester/Tests/testNics/test_network_sriov_stress.py:967
  /root/.jenkins/workspace/spr-test-nicIperfTcpGuestsStress/npxtester/Tests/testNics/test_network_sriov_stress.py:967: PytestUnknownMarkWarning: Unknown pytest.mark.SriovVfIperf - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/mark.html
    @pytest.mark.SriovVfIperf

npxtester/Tests/testNics/test_network_sriov_stress.py:1106
  /root/.jenkins/workspace/spr-test-nicIperfTcpGuestsStress/npxtester/Tests/testNics/test_network_sriov_stress.py:1106: PytestUnknownMarkWarning: Unknown pytest.mark.nicIperfTcpSUTGuestStress - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/mark.html
    @pytest.mark.nicIperfTcpSUTGuestStress

npxtester/Tests/testNics/test_network_sriov_stress.py:1107
  /root/.jenkins/workspace/spr-test-nicIperfTcpGuestsStress/npxtester/Tests/testNics/test_network_sriov_stress.py:1107: PytestUnknownMarkWarning: Unknown pytest.mark.SriovVfIperf - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/mark.html
    @pytest.mark.SriovVfIperf

npxtester/Tests/testNics/test_nics.py:119
  /root/.jenkins/workspace/spr-test-nicIperfTcpGuestsStress/npxtester/Tests/testNics/test_nics.py:119: PytestUnknownMarkWarning: Unknown pytest.mark.nicSimple - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/mark.html
    @pytest.mark.nicSimple

npxtester/Tests/testNics/test_nics.py:156
  /root/.jenkins/workspace/spr-test-nicIperfTcpGuestsStress/npxtester/Tests/testNics/test_nics.py:156: PytestUnknownMarkWarning: Unknown pytest.mark.nicSimple - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/mark.html
    @pytest.mark.nicSimple

npxtester/Tests/testNics/test_nics.py:157
  /root/.jenkins/workspace/spr-test-nicIperfTcpGuestsStress/npxtester/Tests/testNics/test_nics.py:157: PytestUnknownMarkWarning: Unknown pytest.mark.connect - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/mark.html
    @pytest.mark.connect

npxtester/Tests/testNics/test_nics.py:189
  /root/.jenkins/workspace/spr-test-nicIperfTcpGuestsStress/npxtester/Tests/testNics/test_nics.py:189: PytestUnknownMarkWarning: Unknown pytest.mark.nicSimple - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/mark.html
    @pytest.mark.nicSimple

npxtester/Tests/testNics/test_nics.py:190
  /root/.jenkins/workspace/spr-test-nicIperfTcpGuestsStress/npxtester/Tests/testNics/test_nics.py:190: PytestUnknownMarkWarning: Unknown pytest.mark.static_ip - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/mark.html
    @pytest.mark.static_ip

npxtester/Tests/testNics/test_nics.py:221
  /root/.jenkins/workspace/spr-test-nicIperfTcpGuestsStress/npxtester/Tests/testNics/test_nics.py:221: PytestUnknownMarkWarning: Unknown pytest.mark.nicSimple - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/mark.html
    @pytest.mark.nicSimple

npxtester/Tests/testNics/test_nics.py:222
  /root/.jenkins/workspace/spr-test-nicIperfTcpGuestsStress/npxtester/Tests/testNics/test_nics.py:222: PytestUnknownMarkWarning: Unknown pytest.mark.test - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/mark.html
    @pytest.mark.test

npxtester/Tests/testNics/test_nics.py:308
  /root/.jenkins/workspace/spr-test-nicIperfTcpGuestsStress/npxtester/Tests/testNics/test_nics.py:308: PytestUnknownMarkWarning: Unknown pytest.mark.nicSimple - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/mark.html
    @pytest.mark.nicSimple

npxtester/Tests/testNics/test_nics.py:334
  /root/.jenkins/workspace/spr-test-nicIperfTcpGuestsStress/npxtester/Tests/testNics/test_nics.py:334: PytestUnknownMarkWarning: Unknown pytest.mark.nicSimple - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/mark.html
    @pytest.mark.nicSimple

npxtester/Tests/testNics/test_nics.py:377
  /root/.jenkins/workspace/spr-test-nicIperfTcpGuestsStress/npxtester/Tests/testNics/test_nics.py:377: PytestUnknownMarkWarning: Unknown pytest.mark.nicSimple - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/mark.html
    @pytest.mark.nicSimple

-- Docs: https://docs.pytest.org/en/stable/warnings.html
- generated html file: file:///root/testconfig/testlogs/HtmlReport/nicIperfTcpGuestStress_ipv4_report.html -
=========================== short test summary info ============================
FAILED npxtester/Tests/testNics/test_network_sriov_stress.py::Test_Network_SRIOV_Stress::test_PI_Iperf_TCP_Stress_Guests[ipv4-rvm2.img-rvm1.img]
FAILED npxtester/Tests/testNics/test_network_sriov_stress.py::Test_Network_SRIOV_Stress::test_PI_Iperf_TCP_Stress_Guests[ipv6-rvm2.img-rvm1.img]
========== 2 failed, 18 deselected, 19 warnings in 847.46s (0:14:07) ===========
[8mha:////4DDaF6xD1n97fCJC17HEPtC4MvFSxjBMoUPdpyGs71EZAAAApR+LCAAAAAAAAP9tjTEOwjAQBC9BFLSUPOIioEIoFa3lhheYxBgn1l2wHZyKF/E1/oBFJCq2WO1sM683LIOHmr3BTlNvKTQWBzeavDCx76+OE3Z8wYYpsNModZLc6tOMkqOGOUUJCwErTY3jYMlEWItOPVTlFJnqHH3+jgJK297hCYXI5qh8/MLkYXMb28D08/wVwDREKHeHXPvt8AGMzKKgvgAAAA==[0m[Pipeline] echo
1
[8mha:////4JdwCG2vyNU1vR63Cq0h1I9fweuZdBzoUYFbNZMa07ZpAAAApR+LCAAAAAAAAP9tjTEOwjAQBC9BFLSUPOIihQohqrRWGl5gYmOcWHfGdkgqXsTX+AMWkajYYrWzzbzesI4BThwM9poGS7Gz6N1o8sKJw3B1PGHPF+yYIjuNrZ5aVrpZsOWkYUlRwkrARlPnOFoyCbailw9ZOUmmOqeQv6OA0qo7PKEQ2ZxkSF+YA+xuo4pMP89fAcw+QVkfcu1r/wFPn4+LvgAAAA==[0m[Pipeline] sh
+ sed -i $'s/\r//g' /root/.jenkins/workspace/spr-test-nicIperfTcpGuestsStress/npxtester/log_analyzer/log_analyzer.sh
[8mha:////4J0lAWMm8HuBR5s3oE3lokuIt9KB2+AHQUkjEiJ+aQGpAAAApR+LCAAAAAAAAP9tjTEOwjAQBC9BFLSUPMKRSIUQVVorDS8w8WGcWHfGdkgqXsTX+AMWkajYYrWzzbzesI4BThyM6JEGS7GzwrvR5CUmDsPV8SR6voiOKbJD0eLUssZmwZYTwpKihJWEDVLnOFoyCbayVw9VOUWmOqeQv6OE0uo7PKGQ2ZxUSF+YA+xuo45MP89fAcw+Qbk/5Kpr/wEOrpSSvgAAAA==[0m[Pipeline] sh
+ chmod a+x /root/.jenkins/workspace/spr-test-nicIperfTcpGuestsStress/npxtester/log_analyzer/log_analyzer.sh
[8mha:////4Mt0DSsxkJzZfVcF7hGhEOllvDy/ttdaA/Rf0YiZvcahAAAApR+LCAAAAAAAAP9tjTEOwjAQBC9BFLSUPOIiAQ1CqWgtN7zAJMY4se6C7eBUvIiv8QcsIlGxxWpnm3m9YRk81OwNdpp6S6GxOLjR5IWJfX91nLDjCzZMgZ1GqZPkVp9mlBw1zClKWAhYaWocB0smwlp06qEqp8hU5+jzdxRQ2vYOTyhENkfl4xcmD5vb2Aamn+evAKYhQrk95Nrthw/JONXdvgAAAA==[0m[Pipeline] sh
+ sh /root/.jenkins/workspace/spr-test-nicIperfTcpGuestsStress/npxtester/log_analyzer/log_analyzer.sh
[8mha:////4BJ3niM699yfMaO4XlYckMNVxHBxF/A/6tXrT01aXGOTAAAAph+LCAAAAAAAAP9tjTEOwjAQBC9BFLSUPOIigSgQSkVrueEFJjHGiXUXbAen4kV8jT9gEYmKLVY728zrDcvgoWZvsNPUWwqNxcGNJi9M7Pur44QdX7BhCuw0Sp0kt/o0o+SoYU5RwkLASlPjOFgyEdaiUw9VOUWmOkefv6OA0rZ3eEIhsjkqH78wedjcxjYw/Tx/BTANQ4Ryt8+1PXwARMxJg74AAAA=[0m[Pipeline] }
[8mha:////4KLOGR+83vgrLFidGueNeEu4h+87+yS5qW1q0kigPKEkAAAAph+LCAAAAAAAAP9tjTEOwjAQBC9BFLSUPOIigYSQUCpayw0vMIkxTqy7YDs4FS/ia/wBi0hUbLHa2WZeb1gGDzV7g52m3lJoLA5uNHlhYt9fHSfs+IINU2CnUeokudWnGSVHDXOKEhYCVpoax8GSibAWnXqoyiky1Tn6/B0FlLa9wxMKkc1R+fiFycPmNraB6ef5K4BpGCKUu32u7eEDfI7acr4AAAA=[0m[Pipeline] // script
[8mha:////4B/bjeg5xruNbbx3kITLupXWvVAJcKllvbrOrw34K5MTAAAApR+LCAAAAAAAAP9tjTEOwjAQBC9BFLSUPOIiQZECUaW10vACExvjxLoztkNS8SK+xh+wiETFFqudbeb1hnUMcOJgsNc0WIqdRe9GkxdOHIar4wl7vmDHFNlpbPXUstLNgi0nDUuKElYCNpo6x9GSSbAVvXzIykky1TmF/B0FlFbd4QmFyOYkQ/rCHGB3G1Vk+nn+CmD2PkF5qHPt6w9IQDkpvgAAAA==[0m[Pipeline] }
[8mha:////4Pysn2p6Cuaw38A5WKCzX3hZbaQrVsudvseeZZRTcVjBAAAAph+LCAAAAAAAAP9tjTEOwjAQBC9BFLSUPOIigYSQUCpayw0vMIkxTqy7YDs4FS/ia/wBi0hUbLHa2WZeb1gGDzV7g52m3lJoLA5uNHlhYt9fHSfs+IINU2CnUeokudWnGSVHDXOKEhYCVpoax8GSibAWnXqoyiky1Tn6/B0FlLa9wxMKkc1R+fiFycPmNraB6ef5K4BpGCKUu0Ou7f4DC8Jor74AAAA=[0m[Pipeline] // stage
[8mha:////4AtNwyaW/AZqBd3OKxZrkWfAC6zB3HxngMFQ9sJmqFs1AAAAox+LCAAAAAAAAP9tjTEOwjAQBDdBFLSUPMIpoEGIitZKwwtMYowT6y7YF5KKF/E1/kBEJCq22plmXm8sU8SRo1ONpdZTqrzqQu+mpwaO7TXwoBq+qIopcbCqtEPJtT3NWLJYzMtyLDRWlqrAyZMTrHVjHqYIhlxxlji5g0bu6zueyPRUFhPlC2PE5tbXienX+RvA2HWCfLsXZLsP/+idkr0AAAA=[0m[Pipeline] }
[8mha:////4I5dJP3UyABwbWbQZBRGWAtgfXC/GfHsQ3SW1rlV0+rIAAAAox+LCAAAAAAAAP9tjTEOwjAQBDdBFLSUPMJBgg5R0VppeIFJjHFi3QX7QlLxIr7GH4iIRMVWO9PM641lijhydKqx1HpKlVdd6N301MCxvQYeVMMXVTElDlaVdii5tqcZSxaLeVmOhcbKUhU4eXKCtW7MwxTBkCvOEid30Mh9fccTmZ7KYqJ8YYzY3Po6Mf06fwMYu06Q77eCbPcBlS/sHL0AAAA=[0m[Pipeline] // node
[8mha:////4OCxxHdXTRYePL6pNSOSjI/nVmiKF6Ardumg4UkWHzykAAAAox+LCAAAAAAAAP9tjTEOwjAQBDdBFLSUPMIRiA5R0VppeIFJjHFi3QX7QlLxIr7GH4iIRMVWO9PM641lijhydKqx1HpKlVdd6N301MCxvQYeVMMXVTElDlaVdii5tqcZSxaLeVmOhcbKUhU4eXKCtW7MwxTBkCvOEid30Mh9fccTmZ7KYqJ8YYzY3Po6Mf06fwMYu06Q77eCbPcBszaLVr0AAAA=[0m[Pipeline] End of Pipeline
Finished: FAILURE
